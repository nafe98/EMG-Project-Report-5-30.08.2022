{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf8ee932",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f663fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511af272",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04fd19b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emg1</th>\n",
       "      <th>emg2</th>\n",
       "      <th>emg3</th>\n",
       "      <th>emg4</th>\n",
       "      <th>emg5</th>\n",
       "      <th>emg6</th>\n",
       "      <th>emg7</th>\n",
       "      <th>emg8</th>\n",
       "      <th>emg9</th>\n",
       "      <th>emg10</th>\n",
       "      <th>repetition</th>\n",
       "      <th>rerepetition</th>\n",
       "      <th>stimulus</th>\n",
       "      <th>restimulus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51531</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0610</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0269</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55310</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.1270</td>\n",
       "      <td>0.0757</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11272</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.1929</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18105</th>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.2319</td>\n",
       "      <td>0.0635</td>\n",
       "      <td>0.0269</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.0610</td>\n",
       "      <td>0.2539</td>\n",
       "      <td>0.0586</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62441</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0806</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         emg1    emg2    emg3    emg4    emg5    emg6    emg7    emg8    emg9  \\\n",
       "51531  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0610  0.0562  0.0024   \n",
       "55310  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.1270  0.0757  0.0024   \n",
       "11272  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0195  0.0049  0.0024   \n",
       "18105  0.0146  0.2319  0.0635  0.0269  0.0024  0.0024  0.0195  0.0610  0.2539   \n",
       "62441  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0806  0.0366  0.0024   \n",
       "\n",
       "        emg10  repetition  rerepetition  stimulus  restimulus  \n",
       "51531  0.0269           2             0         7           0  \n",
       "55310  0.1099           6             0         7           0  \n",
       "11272  0.1929           4             4         2           2  \n",
       "18105  0.0586           2             2         3           3  \n",
       "62441  0.0195           0             0         0           0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_excel('Dataset1 .xlsx')\n",
    "raw_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80369ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101014 entries, 0 to 101013\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   emg1          101014 non-null  float64\n",
      " 1   emg2          101014 non-null  float64\n",
      " 2   emg3          101014 non-null  float64\n",
      " 3   emg4          101014 non-null  float64\n",
      " 4   emg5          101014 non-null  float64\n",
      " 5   emg6          101014 non-null  float64\n",
      " 6   emg7          101014 non-null  float64\n",
      " 7   emg8          101014 non-null  float64\n",
      " 8   emg9          101014 non-null  float64\n",
      " 9   emg10         101014 non-null  float64\n",
      " 10  repetition    101014 non-null  int64  \n",
      " 11  rerepetition  101014 non-null  int64  \n",
      " 12  stimulus      101014 non-null  int64  \n",
      " 13  restimulus    101014 non-null  int64  \n",
      "dtypes: float64(10), int64(4)\n",
      "memory usage: 10.8 MB\n"
     ]
    }
   ],
   "source": [
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "109445f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emg1</th>\n",
       "      <th>emg2</th>\n",
       "      <th>emg3</th>\n",
       "      <th>emg4</th>\n",
       "      <th>emg5</th>\n",
       "      <th>emg6</th>\n",
       "      <th>emg7</th>\n",
       "      <th>emg8</th>\n",
       "      <th>emg9</th>\n",
       "      <th>emg10</th>\n",
       "      <th>repetition</th>\n",
       "      <th>rerepetition</th>\n",
       "      <th>stimulus</th>\n",
       "      <th>restimulus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>101014.000000</td>\n",
       "      <td>101014.000000</td>\n",
       "      <td>101014.000000</td>\n",
       "      <td>101014.000000</td>\n",
       "      <td>101014.000000</td>\n",
       "      <td>101014.000000</td>\n",
       "      <td>101014.000000</td>\n",
       "      <td>101014.000000</td>\n",
       "      <td>101014.000000</td>\n",
       "      <td>101014.000000</td>\n",
       "      <td>101014.000000</td>\n",
       "      <td>101014.000000</td>\n",
       "      <td>101014.000000</td>\n",
       "      <td>101014.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.039693</td>\n",
       "      <td>0.086158</td>\n",
       "      <td>0.041308</td>\n",
       "      <td>0.012502</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.005367</td>\n",
       "      <td>0.167648</td>\n",
       "      <td>0.116476</td>\n",
       "      <td>0.073460</td>\n",
       "      <td>0.054120</td>\n",
       "      <td>3.372948</td>\n",
       "      <td>2.055349</td>\n",
       "      <td>3.985665</td>\n",
       "      <td>2.329905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.127180</td>\n",
       "      <td>0.231539</td>\n",
       "      <td>0.101912</td>\n",
       "      <td>0.031334</td>\n",
       "      <td>0.009796</td>\n",
       "      <td>0.021238</td>\n",
       "      <td>0.403823</td>\n",
       "      <td>0.174862</td>\n",
       "      <td>0.156381</td>\n",
       "      <td>0.112567</td>\n",
       "      <td>3.497555</td>\n",
       "      <td>3.188164</td>\n",
       "      <td>4.162080</td>\n",
       "      <td>3.691976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.039100</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.046400</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.017100</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.024400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.129400</td>\n",
       "      <td>0.109900</td>\n",
       "      <td>0.068400</td>\n",
       "      <td>0.048800</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.399900</td>\n",
       "      <td>2.480500</td>\n",
       "      <td>1.340300</td>\n",
       "      <td>0.446800</td>\n",
       "      <td>0.293000</td>\n",
       "      <td>0.639600</td>\n",
       "      <td>4.660600</td>\n",
       "      <td>3.000500</td>\n",
       "      <td>1.752900</td>\n",
       "      <td>1.599100</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                emg1           emg2           emg3           emg4  \\\n",
       "count  101014.000000  101014.000000  101014.000000  101014.000000   \n",
       "mean        0.039693       0.086158       0.041308       0.012502   \n",
       "std         0.127180       0.231539       0.101912       0.031334   \n",
       "min         0.002400       0.000000       0.002400       0.000000   \n",
       "25%         0.002400       0.002400       0.002400       0.002400   \n",
       "50%         0.002400       0.002400       0.002400       0.002400   \n",
       "75%         0.024400       0.002400       0.012200       0.002400   \n",
       "max         2.399900       2.480500       1.340300       0.446800   \n",
       "\n",
       "                emg5           emg6           emg7           emg8  \\\n",
       "count  101014.000000  101014.000000  101014.000000  101014.000000   \n",
       "mean        0.003868       0.005367       0.167648       0.116476   \n",
       "std         0.009796       0.021238       0.403823       0.174862   \n",
       "min         0.002400       0.000000       0.002400       0.002400   \n",
       "25%         0.002400       0.002400       0.009800       0.039100   \n",
       "50%         0.002400       0.002400       0.046400       0.061000   \n",
       "75%         0.002400       0.002400       0.129400       0.109900   \n",
       "max         0.293000       0.639600       4.660600       3.000500   \n",
       "\n",
       "                emg9          emg10     repetition   rerepetition  \\\n",
       "count  101014.000000  101014.000000  101014.000000  101014.000000   \n",
       "mean        0.073460       0.054120       3.372948       2.055349   \n",
       "std         0.156381       0.112567       3.497555       3.188164   \n",
       "min         0.000000       0.002400       0.000000       0.000000   \n",
       "25%         0.002400       0.004900       0.000000       0.000000   \n",
       "50%         0.002400       0.017100       2.000000       0.000000   \n",
       "75%         0.068400       0.048800       6.000000       4.000000   \n",
       "max         1.752900       1.599100      10.000000      10.000000   \n",
       "\n",
       "            stimulus     restimulus  \n",
       "count  101014.000000  101014.000000  \n",
       "mean        3.985665       2.329905  \n",
       "std         4.162080       3.691976  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.000000       0.000000  \n",
       "50%         3.000000       0.000000  \n",
       "75%         8.000000       4.000000  \n",
       "max        12.000000      12.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0b9a2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Dependent values and their counts :\n",
      "0     39063\n",
      "2      5174\n",
      "4      5173\n",
      "5      5173\n",
      "12     5173\n",
      "8      5172\n",
      "7      5171\n",
      "6      5170\n",
      "11     5166\n",
      "3      5158\n",
      "1      5149\n",
      "10     5137\n",
      "9      5135\n",
      "Name: stimulus, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique Dependent values and their counts :\")\n",
    "print(raw_data[\"stimulus\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54420ec4",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a811198b",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_names = raw_data[ (raw_data['stimulus'] != raw_data['restimulus'])].index\n",
    "raw_data.drop(index_names, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "556cd92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_names = raw_data[ (raw_data['repetition'] != raw_data['rerepetition'])].index\n",
    "raw_data.drop(index_names, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c91744f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = raw_data.iloc[:,0:10]\n",
    "y = raw_data.stimulus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7289b270",
   "metadata": {},
   "source": [
    "# Applying Simple Deeplearning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73f5ef33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras import activations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152f7160",
   "metadata": {},
   "source": [
    "# One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfb77d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "277dc3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding for categorical labels\n",
    "import keras\n",
    "y = keras.utils.to_categorical(y, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7358f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "input_dim = X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3088a1",
   "metadata": {},
   "source": [
    "# Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bd820f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "standardscaler=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a118694",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pd.DataFrame(standardscaler.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6e2f38b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.124694</td>\n",
       "      <td>-0.428949</td>\n",
       "      <td>-0.447634</td>\n",
       "      <td>-0.376741</td>\n",
       "      <td>-0.171824</td>\n",
       "      <td>0.139046</td>\n",
       "      <td>-0.439076</td>\n",
       "      <td>-0.441237</td>\n",
       "      <td>-0.537378</td>\n",
       "      <td>-0.250667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.057307</td>\n",
       "      <td>-0.428949</td>\n",
       "      <td>-0.447634</td>\n",
       "      <td>-0.376741</td>\n",
       "      <td>-0.171824</td>\n",
       "      <td>-0.060491</td>\n",
       "      <td>-0.439076</td>\n",
       "      <td>-0.478142</td>\n",
       "      <td>-0.537378</td>\n",
       "      <td>-0.289053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.040804</td>\n",
       "      <td>-0.428949</td>\n",
       "      <td>-0.447634</td>\n",
       "      <td>-0.376741</td>\n",
       "      <td>-0.171824</td>\n",
       "      <td>-0.060491</td>\n",
       "      <td>-0.439076</td>\n",
       "      <td>-0.490275</td>\n",
       "      <td>-0.537378</td>\n",
       "      <td>-0.327440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.040804</td>\n",
       "      <td>-0.428949</td>\n",
       "      <td>-0.447634</td>\n",
       "      <td>-0.376741</td>\n",
       "      <td>-0.171824</td>\n",
       "      <td>-0.060491</td>\n",
       "      <td>-0.439076</td>\n",
       "      <td>-0.515047</td>\n",
       "      <td>-0.537378</td>\n",
       "      <td>-0.384629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.010081</td>\n",
       "      <td>-0.428949</td>\n",
       "      <td>-0.447634</td>\n",
       "      <td>-0.376741</td>\n",
       "      <td>-0.171824</td>\n",
       "      <td>-0.162295</td>\n",
       "      <td>-0.439076</td>\n",
       "      <td>-0.502914</td>\n",
       "      <td>-0.537378</td>\n",
       "      <td>-0.404214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75038</th>\n",
       "      <td>-0.329139</td>\n",
       "      <td>-0.428949</td>\n",
       "      <td>-0.447634</td>\n",
       "      <td>-0.376741</td>\n",
       "      <td>0.048955</td>\n",
       "      <td>-0.162295</td>\n",
       "      <td>-0.439076</td>\n",
       "      <td>-0.502914</td>\n",
       "      <td>-0.537378</td>\n",
       "      <td>-0.499790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75039</th>\n",
       "      <td>-0.329139</td>\n",
       "      <td>-0.428949</td>\n",
       "      <td>-0.447634</td>\n",
       "      <td>-0.376741</td>\n",
       "      <td>-0.171824</td>\n",
       "      <td>-0.162295</td>\n",
       "      <td>-0.439076</td>\n",
       "      <td>-0.515047</td>\n",
       "      <td>-0.537378</td>\n",
       "      <td>-0.499790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75040</th>\n",
       "      <td>-0.329139</td>\n",
       "      <td>-0.428949</td>\n",
       "      <td>-0.447634</td>\n",
       "      <td>-0.376741</td>\n",
       "      <td>-0.171824</td>\n",
       "      <td>-0.162295</td>\n",
       "      <td>-0.439076</td>\n",
       "      <td>-0.515047</td>\n",
       "      <td>-0.537378</td>\n",
       "      <td>-0.461403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75041</th>\n",
       "      <td>-0.329139</td>\n",
       "      <td>-0.428949</td>\n",
       "      <td>-0.447634</td>\n",
       "      <td>-0.376741</td>\n",
       "      <td>-0.171824</td>\n",
       "      <td>-0.162295</td>\n",
       "      <td>-0.439076</td>\n",
       "      <td>-0.502914</td>\n",
       "      <td>-0.537378</td>\n",
       "      <td>-0.461403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75042</th>\n",
       "      <td>-0.329139</td>\n",
       "      <td>-0.428949</td>\n",
       "      <td>-0.447634</td>\n",
       "      <td>-0.376741</td>\n",
       "      <td>-0.171824</td>\n",
       "      <td>-0.162295</td>\n",
       "      <td>-0.439076</td>\n",
       "      <td>-0.490275</td>\n",
       "      <td>-0.537378</td>\n",
       "      <td>-0.499790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75043 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.124694 -0.428949 -0.447634 -0.376741 -0.171824  0.139046 -0.439076   \n",
       "1      0.057307 -0.428949 -0.447634 -0.376741 -0.171824 -0.060491 -0.439076   \n",
       "2      0.040804 -0.428949 -0.447634 -0.376741 -0.171824 -0.060491 -0.439076   \n",
       "3      0.040804 -0.428949 -0.447634 -0.376741 -0.171824 -0.060491 -0.439076   \n",
       "4     -0.010081 -0.428949 -0.447634 -0.376741 -0.171824 -0.162295 -0.439076   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "75038 -0.329139 -0.428949 -0.447634 -0.376741  0.048955 -0.162295 -0.439076   \n",
       "75039 -0.329139 -0.428949 -0.447634 -0.376741 -0.171824 -0.162295 -0.439076   \n",
       "75040 -0.329139 -0.428949 -0.447634 -0.376741 -0.171824 -0.162295 -0.439076   \n",
       "75041 -0.329139 -0.428949 -0.447634 -0.376741 -0.171824 -0.162295 -0.439076   \n",
       "75042 -0.329139 -0.428949 -0.447634 -0.376741 -0.171824 -0.162295 -0.439076   \n",
       "\n",
       "              7         8         9  \n",
       "0     -0.441237 -0.537378 -0.250667  \n",
       "1     -0.478142 -0.537378 -0.289053  \n",
       "2     -0.490275 -0.537378 -0.327440  \n",
       "3     -0.515047 -0.537378 -0.384629  \n",
       "4     -0.502914 -0.537378 -0.404214  \n",
       "...         ...       ...       ...  \n",
       "75038 -0.502914 -0.537378 -0.499790  \n",
       "75039 -0.515047 -0.537378 -0.499790  \n",
       "75040 -0.515047 -0.537378 -0.461403  \n",
       "75041 -0.502914 -0.537378 -0.461403  \n",
       "75042 -0.490275 -0.537378 -0.499790  \n",
       "\n",
       "[75043 rows x 10 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65cfb75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(sc, y, test_size = 0.2, random_state = 39)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1df00dc",
   "metadata": {},
   "source": [
    "# 1. Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29124422",
   "metadata": {},
   "outputs": [],
   "source": [
    "visible = Input(shape=(input_dim,))\n",
    "hidden1 = Dense(64, activation='relu')(visible)\n",
    "hidden2 = Dense(64, activation='relu')(hidden1)\n",
    "hidden3 = Dense(64, activation='relu')(hidden2)\n",
    "output = Dense(num_classes, activation='softmax')(hidden3)\n",
    "model = Model(inputs=visible, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b326346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 10)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                704       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 13)                845       \n",
      "=================================================================\n",
      "Total params: 9,869\n",
      "Trainable params: 9,869\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# summarize layers\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8e6043",
   "metadata": {},
   "source": [
    "# 2. Compile Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc7fff06",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='RMSprop', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389c05ec",
   "metadata": {},
   "source": [
    "# 3. Fit Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94fde1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6004/6004 [==============================] - 6s 975us/step - loss: 0.0225 - accuracy: 0.8083\n",
      "Epoch 2/50\n",
      "6004/6004 [==============================] - 6s 998us/step - loss: 0.0183 - accuracy: 0.8467\n",
      "Epoch 3/50\n",
      "6004/6004 [==============================] - 6s 976us/step - loss: 0.0175 - accuracy: 0.8555\n",
      "Epoch 4/50\n",
      "6004/6004 [==============================] - 6s 1ms/step - loss: 0.0170 - accuracy: 0.8587\n",
      "Epoch 5/50\n",
      "6004/6004 [==============================] - 6s 988us/step - loss: 0.0165 - accuracy: 0.8637\n",
      "Epoch 6/50\n",
      "6004/6004 [==============================] - 6s 974us/step - loss: 0.0163 - accuracy: 0.8653\n",
      "Epoch 7/50\n",
      "6004/6004 [==============================] - 6s 1ms/step - loss: 0.0160 - accuracy: 0.8683\n",
      "Epoch 8/50\n",
      "6004/6004 [==============================] - 6s 994us/step - loss: 0.0159 - accuracy: 0.8699\n",
      "Epoch 9/50\n",
      "6004/6004 [==============================] - 6s 999us/step - loss: 0.0157 - accuracy: 0.8726\n",
      "Epoch 10/50\n",
      "6004/6004 [==============================] - 7s 1ms/step - loss: 0.0155 - accuracy: 0.8727\n",
      "Epoch 11/50\n",
      "6004/6004 [==============================] - 7s 1ms/step - loss: 0.0154 - accuracy: 0.8738\n",
      "Epoch 12/50\n",
      "6004/6004 [==============================] - 6s 1ms/step - loss: 0.0155 - accuracy: 0.8742\n",
      "Epoch 13/50\n",
      "6004/6004 [==============================] - 6s 1ms/step - loss: 0.0153 - accuracy: 0.8759\n",
      "Epoch 14/50\n",
      "6004/6004 [==============================] - 6s 1ms/step - loss: 0.0153 - accuracy: 0.8764\n",
      "Epoch 15/50\n",
      "6004/6004 [==============================] - 7s 1ms/step - loss: 0.0152 - accuracy: 0.8774\n",
      "Epoch 16/50\n",
      "6004/6004 [==============================] - 6s 1ms/step - loss: 0.0151 - accuracy: 0.8781\n",
      "Epoch 17/50\n",
      "6004/6004 [==============================] - 6s 1ms/step - loss: 0.0152 - accuracy: 0.8773\n",
      "Epoch 18/50\n",
      "6004/6004 [==============================] - 6s 1ms/step - loss: 0.0151 - accuracy: 0.8789\n",
      "Epoch 19/50\n",
      "6004/6004 [==============================] - 6s 1ms/step - loss: 0.0149 - accuracy: 0.8802\n",
      "Epoch 20/50\n",
      "6004/6004 [==============================] - 6s 1ms/step - loss: 0.0149 - accuracy: 0.8806\n",
      "Epoch 21/50\n",
      "6004/6004 [==============================] - 6s 1ms/step - loss: 0.0148 - accuracy: 0.8810\n",
      "Epoch 22/50\n",
      "6004/6004 [==============================] - 6s 997us/step - loss: 0.0148 - accuracy: 0.8818\n",
      "Epoch 23/50\n",
      "6004/6004 [==============================] - 7s 1ms/step - loss: 0.0147 - accuracy: 0.8830\n",
      "Epoch 24/50\n",
      "6004/6004 [==============================] - 7s 1ms/step - loss: 0.0148 - accuracy: 0.8817\n",
      "Epoch 25/50\n",
      "6004/6004 [==============================] - 6s 1ms/step - loss: 0.0149 - accuracy: 0.8817: \n",
      "Epoch 26/50\n",
      "6004/6004 [==============================] - 6s 1ms/step - loss: 0.0149 - accuracy: 0.8811\n",
      "Epoch 27/50\n",
      "6004/6004 [==============================] - 9s 2ms/step - loss: 0.0147 - accuracy: 0.8835\n",
      "Epoch 28/50\n",
      "6004/6004 [==============================] - 6s 953us/step - loss: 0.0149 - accuracy: 0.8814\n",
      "Epoch 29/50\n",
      "6004/6004 [==============================] - 6s 1ms/step - loss: 0.0147 - accuracy: 0.8832\n",
      "Epoch 30/50\n",
      "6004/6004 [==============================] - 6s 1ms/step - loss: 0.0148 - accuracy: 0.8830: 0s - loss: 0.0148 - accuracy: \n",
      "Epoch 31/50\n",
      "6004/6004 [==============================] - 6s 976us/step - loss: 0.0148 - accuracy: 0.8836\n",
      "Epoch 32/50\n",
      "6004/6004 [==============================] - 6s 980us/step - loss: 0.0149 - accuracy: 0.8823\n",
      "Epoch 33/50\n",
      "6004/6004 [==============================] - 6s 929us/step - loss: 0.0148 - accuracy: 0.88390s - loss: 0.0147 - accuracy: 0. - ETA: 0s - loss: 0.0147 - accu\n",
      "Epoch 34/50\n",
      "6004/6004 [==============================] - 5s 906us/step - loss: 0.0147 - accuracy: 0.8843\n",
      "Epoch 35/50\n",
      "6004/6004 [==============================] - 6s 948us/step - loss: 0.0148 - accuracy: 0.8842\n",
      "Epoch 36/50\n",
      "6004/6004 [==============================] - 6s 918us/step - loss: 0.0149 - accuracy: 0.8826\n",
      "Epoch 37/50\n",
      "6004/6004 [==============================] - 6s 924us/step - loss: 0.0148 - accuracy: 0.8830\n",
      "Epoch 38/50\n",
      "6004/6004 [==============================] - 7s 1ms/step - loss: 0.0148 - accuracy: 0.8845: \n",
      "Epoch 39/50\n",
      "6004/6004 [==============================] - 6s 968us/step - loss: 0.0147 - accuracy: 0.8850\n",
      "Epoch 40/50\n",
      "6004/6004 [==============================] - 6s 970us/step - loss: 0.0149 - accuracy: 0.8839\n",
      "Epoch 41/50\n",
      "6004/6004 [==============================] - 6s 945us/step - loss: 0.0147 - accuracy: 0.8848\n",
      "Epoch 42/50\n",
      "6004/6004 [==============================] - 9s 1ms/step - loss: 0.0148 - accuracy: 0.8842\n",
      "Epoch 43/50\n",
      "6004/6004 [==============================] - 9s 1ms/step - loss: 0.0147 - accuracy: 0.8864\n",
      "Epoch 44/50\n",
      "6004/6004 [==============================] - 6s 1ms/step - loss: 0.0149 - accuracy: 0.8849\n",
      "Epoch 45/50\n",
      "6004/6004 [==============================] - 6s 987us/step - loss: 0.0150 - accuracy: 0.8845\n",
      "Epoch 46/50\n",
      "6004/6004 [==============================] - 6s 941us/step - loss: 0.0148 - accuracy: 0.8849\n",
      "Epoch 47/50\n",
      "6004/6004 [==============================] - 7s 1ms/step - loss: 0.0149 - accuracy: 0.8844\n",
      "Epoch 48/50\n",
      "6004/6004 [==============================] - 6s 986us/step - loss: 0.0149 - accuracy: 0.8836\n",
      "Epoch 49/50\n",
      "6004/6004 [==============================] - 6s 1ms/step - loss: 0.0149 - accuracy: 0.8844\n",
      "Epoch 50/50\n",
      "6004/6004 [==============================] - 6s 952us/step - loss: 0.0148 - accuracy: 0.8851\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=10, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5bcc9a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c731857",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('final_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d66db39",
   "metadata": {},
   "source": [
    "# 4. Evaluate Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d520326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470/470 [==============================] - 0s 792us/step - loss: 0.0161 - accuracy: 0.8743\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5b45e2",
   "metadata": {},
   "source": [
    "# 5. Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "422fe114",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f80315aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.1980672e-01, 7.6573621e-03, 4.8059208e-04, ..., 1.8260259e-02,\n",
       "        2.6536020e-03, 3.0118886e-02],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "        1.0000000e+00, 0.0000000e+00],\n",
       "       [8.8786113e-01, 1.3788684e-02, 2.2883685e-03, ..., 4.0472969e-02,\n",
       "        1.4810652e-03, 3.1818960e-02],\n",
       "       ...,\n",
       "       [9.9540979e-01, 4.7232850e-05, 1.7427649e-04, ..., 2.5241838e-05,\n",
       "        5.2355622e-06, 1.6430040e-08],\n",
       "       [1.9680709e-18, 1.0000000e+00, 5.7528862e-09, ..., 1.6861816e-34,\n",
       "        0.0000000e+00, 6.8700743e-20],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "        3.4775835e-04, 0.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f838c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot graph\n",
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='multilayer_perceptron_graph.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43a5a95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
