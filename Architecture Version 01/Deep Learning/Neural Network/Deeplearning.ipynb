{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5146ed0c",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3045e9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42648960",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6cab329",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emg1</th>\n",
       "      <th>emg2</th>\n",
       "      <th>emg3</th>\n",
       "      <th>emg4</th>\n",
       "      <th>emg5</th>\n",
       "      <th>emg6</th>\n",
       "      <th>emg7</th>\n",
       "      <th>emg8</th>\n",
       "      <th>emg9</th>\n",
       "      <th>emg10</th>\n",
       "      <th>repetition</th>\n",
       "      <th>rerepetition</th>\n",
       "      <th>stimulus</th>\n",
       "      <th>restimulus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32423</th>\n",
       "      <td>0.2515</td>\n",
       "      <td>1.3086</td>\n",
       "      <td>0.4321</td>\n",
       "      <td>0.0854</td>\n",
       "      <td>0.0781</td>\n",
       "      <td>0.1953</td>\n",
       "      <td>2.9834</td>\n",
       "      <td>0.6372</td>\n",
       "      <td>0.5371</td>\n",
       "      <td>0.1855</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8785</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76706</th>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.0757</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84760</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0854</td>\n",
       "      <td>0.0439</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19154</th>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0537</td>\n",
       "      <td>0.0317</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0757</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83626</th>\n",
       "      <td>0.0537</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0293</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.1074</td>\n",
       "      <td>0.0610</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31766</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61792</th>\n",
       "      <td>0.1929</td>\n",
       "      <td>0.0488</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.0879</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.4712</td>\n",
       "      <td>0.4102</td>\n",
       "      <td>0.3174</td>\n",
       "      <td>0.1074</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50694</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0659</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93173</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0415</td>\n",
       "      <td>0.0317</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0220</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19453</th>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0269</td>\n",
       "      <td>0.0537</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81707</th>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0513</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59642</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.3320</td>\n",
       "      <td>0.1074</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83085</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.1245</td>\n",
       "      <td>0.0684</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61449</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0488</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0342</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86351</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>0.0684</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25081</th>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.0269</td>\n",
       "      <td>0.0415</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.2759</td>\n",
       "      <td>0.1782</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.0708</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94508</th>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0903</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.1001</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0830</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89418</th>\n",
       "      <td>0.1172</td>\n",
       "      <td>0.6787</td>\n",
       "      <td>0.0342</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.1001</td>\n",
       "      <td>0.7251</td>\n",
       "      <td>0.2075</td>\n",
       "      <td>0.1807</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38262</th>\n",
       "      <td>0.1123</td>\n",
       "      <td>0.0977</td>\n",
       "      <td>0.4175</td>\n",
       "      <td>0.1538</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0391</td>\n",
       "      <td>1.4038</td>\n",
       "      <td>0.4639</td>\n",
       "      <td>0.9277</td>\n",
       "      <td>0.1416</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92101</th>\n",
       "      <td>0.0415</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.0391</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49783</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0415</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17049</th>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0269</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95598</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0903</td>\n",
       "      <td>0.0342</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0195</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84550</th>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.1831</td>\n",
       "      <td>0.0928</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16307</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0269</td>\n",
       "      <td>0.0513</td>\n",
       "      <td>0.0903</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73187</th>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.0562</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46632</th>\n",
       "      <td>0.1221</td>\n",
       "      <td>0.4810</td>\n",
       "      <td>0.2344</td>\n",
       "      <td>0.0806</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.3198</td>\n",
       "      <td>0.2515</td>\n",
       "      <td>0.3882</td>\n",
       "      <td>0.3833</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52048</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0659</td>\n",
       "      <td>0.0488</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0708</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67681</th>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.2588</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0830</td>\n",
       "      <td>0.1392</td>\n",
       "      <td>0.0806</td>\n",
       "      <td>0.0293</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75603</th>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0415</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9636</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0342</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0757</td>\n",
       "      <td>0.2075</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99464</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0659</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94750</th>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0830</td>\n",
       "      <td>0.0488</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0269</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5535</th>\n",
       "      <td>0.0659</td>\n",
       "      <td>0.4370</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.0439</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.4297</td>\n",
       "      <td>0.1416</td>\n",
       "      <td>0.3296</td>\n",
       "      <td>0.1807</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88952</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0610</td>\n",
       "      <td>0.0537</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24848</th>\n",
       "      <td>0.0317</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0610</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.1196</td>\n",
       "      <td>0.2124</td>\n",
       "      <td>0.1831</td>\n",
       "      <td>0.0586</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68995</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0952</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0220</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47912</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0684</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70771</th>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0806</td>\n",
       "      <td>0.1270</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40754</th>\n",
       "      <td>0.0610</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0806</td>\n",
       "      <td>0.0415</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.9204</td>\n",
       "      <td>0.2881</td>\n",
       "      <td>0.3516</td>\n",
       "      <td>0.1025</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61900</th>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.2832</td>\n",
       "      <td>0.1611</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>0.0317</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11175</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4765</th>\n",
       "      <td>0.0488</td>\n",
       "      <td>0.5444</td>\n",
       "      <td>0.1270</td>\n",
       "      <td>0.0415</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.2930</td>\n",
       "      <td>0.0830</td>\n",
       "      <td>0.3247</td>\n",
       "      <td>0.2319</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13957</th>\n",
       "      <td>0.1001</td>\n",
       "      <td>1.1182</td>\n",
       "      <td>0.1172</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0732</td>\n",
       "      <td>0.1392</td>\n",
       "      <td>0.6177</td>\n",
       "      <td>0.9546</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75051</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36380</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.2051</td>\n",
       "      <td>0.0903</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45209</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0488</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64968</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0220</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76502</th>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.0806</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         emg1    emg2    emg3    emg4    emg5    emg6    emg7    emg8    emg9  \\\n",
       "32423  0.2515  1.3086  0.4321  0.0854  0.0781  0.1953  2.9834  0.6372  0.5371   \n",
       "8785   0.0024  0.0024  0.0024  0.0049  0.0024  0.0024  0.0171  0.0244  0.0024   \n",
       "76706  0.0220  0.0024  0.0024  0.0024  0.0024  0.0024  0.0220  0.0757  0.0024   \n",
       "84760  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0854  0.0439  0.0024   \n",
       "19154  0.0098  0.0024  0.0537  0.0317  0.0024  0.0024  0.0024  0.0757  0.0464   \n",
       "83626  0.0537  0.0024  0.0293  0.0024  0.0024  0.0024  0.1074  0.0610  0.0024   \n",
       "31766  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0122  0.0220   \n",
       "61792  0.1929  0.0488  0.1465  0.0879  0.0024  0.0073  0.4712  0.4102  0.3174   \n",
       "50694  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0659  0.0024   \n",
       "93173  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0415  0.0317  0.0073   \n",
       "19453  0.0122  0.0024  0.0024  0.0024  0.0024  0.0024  0.0269  0.0537  0.0024   \n",
       "81707  0.0098  0.0024  0.0024  0.0024  0.0024  0.0024  0.0562  0.0513  0.0024   \n",
       "59642  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.3320  0.1074  0.0024   \n",
       "83085  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.1245  0.0684  0.0024   \n",
       "61449  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0488  0.0244  0.0024   \n",
       "86351  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.1147  0.0684  0.0024   \n",
       "25081  0.0195  0.0269  0.0415  0.0024  0.0024  0.0024  0.2759  0.1782  0.0366   \n",
       "94508  0.0098  0.0903  0.0049  0.0024  0.0024  0.0024  0.1001  0.1050  0.0146   \n",
       "89418  0.1172  0.6787  0.0342  0.0024  0.0024  0.0024  0.1001  0.7251  0.2075   \n",
       "38262  0.1123  0.0977  0.4175  0.1538  0.0073  0.0391  1.4038  0.4639  0.9277   \n",
       "92101  0.0415  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.1587  0.0391   \n",
       "49783  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0415  0.0024   \n",
       "17049  0.0073  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0269  0.0024   \n",
       "95598  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0903  0.0342  0.0024   \n",
       "84550  0.0244  0.0024  0.0024  0.0024  0.0024  0.0024  0.1831  0.0928  0.0024   \n",
       "16307  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0269  0.0513   \n",
       "73187  0.0220  0.0024  0.0024  0.0024  0.0024  0.0024  0.0366  0.0562  0.0024   \n",
       "46632  0.1221  0.4810  0.2344  0.0806  0.0024  0.0024  0.3198  0.2515  0.3882   \n",
       "52048  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0659  0.0488  0.0024   \n",
       "67681  0.0122  0.2588  0.0024  0.0024  0.0024  0.0024  0.0830  0.1392  0.0806   \n",
       "75603  0.0171  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0415  0.0024   \n",
       "9636   0.0024  0.0342  0.0024  0.0024  0.0024  0.0024  0.0049  0.0244  0.0757   \n",
       "99464  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0073  0.0659  0.0024   \n",
       "94750  0.0122  0.0024  0.0024  0.0024  0.0024  0.0024  0.0830  0.0488  0.0024   \n",
       "5535   0.0659  0.4370  0.1465  0.0439  0.0049  0.0024  0.4297  0.1416  0.3296   \n",
       "88952  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0610  0.0537  0.0024   \n",
       "24848  0.0317  0.0024  0.0610  0.0073  0.0146  0.0024  0.1196  0.2124  0.1831   \n",
       "68995  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0952  0.1099  0.0024   \n",
       "47912  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0684  0.0366  0.0024   \n",
       "70771  0.0049  0.0024  0.0024  0.0024  0.0024  0.0024  0.0806  0.1270  0.0024   \n",
       "40754  0.0610  0.0024  0.0806  0.0415  0.0024  0.0146  0.9204  0.2881  0.3516   \n",
       "61900  0.0366  0.0024  0.0024  0.0024  0.0024  0.0024  0.2832  0.1611  0.1660   \n",
       "11175  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0146  0.0024   \n",
       "4765   0.0488  0.5444  0.1270  0.0415  0.0098  0.0024  0.2930  0.0830  0.3247   \n",
       "13957  0.1001  1.1182  0.1172  0.0146  0.0049  0.0098  0.0732  0.1392  0.6177   \n",
       "75051  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0366  0.0024   \n",
       "36380  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.2051  0.0903  0.0024   \n",
       "45209  0.0024  0.0024  0.0049  0.0024  0.0024  0.0024  0.0146  0.0488  0.0024   \n",
       "64968  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0122  0.0171  0.0024   \n",
       "76502  0.0171  0.0024  0.0024  0.0024  0.0024  0.0024  0.0195  0.0806  0.0024   \n",
       "\n",
       "        emg10  repetition  rerepetition  stimulus  restimulus  \n",
       "32423  0.1855           9             9         4           4  \n",
       "8785   0.0122           1             0         2           0  \n",
       "76706  0.0024           2             0        10           0  \n",
       "84760  0.0073           0             0         0           0  \n",
       "19154  0.0244           3             3         3           3  \n",
       "83626  0.0049          10            10        10          10  \n",
       "31766  0.0171           8             0         4           0  \n",
       "61792  0.1074           4             4         8           8  \n",
       "50694  0.0024           1             0         7           0  \n",
       "93173  0.0220           0             0         0           0  \n",
       "19453  0.0024           0             0         0           0  \n",
       "81707  0.0073           8             0        10           0  \n",
       "59642  0.0562           0             0         0           0  \n",
       "83085  0.0024           0             9         0          10  \n",
       "61449  0.0342           0             0         0           0  \n",
       "86351  0.0244           3             0        11           0  \n",
       "25081  0.0708          10            10         3           3  \n",
       "94508  0.0830           3             3        12          12  \n",
       "89418  0.1807           7             7        11          11  \n",
       "38262  0.1416           6             6         5           5  \n",
       "92101  0.0024          10            10        11          11  \n",
       "49783  0.0024           0             0         0           0  \n",
       "17049  0.0024           0             0         0           0  \n",
       "95598  0.0195           4             0        12           0  \n",
       "84550  0.0244           1             0        11           0  \n",
       "16307  0.0903          10            10         2           2  \n",
       "73187  0.0024           0             0         0           0  \n",
       "46632  0.3833           6             6         6           6  \n",
       "52048  0.0708           0             0         0           0  \n",
       "67681  0.0293           1             1         9           9  \n",
       "75603  0.0024           0             0         0           0  \n",
       "9636   0.2075           2             2         2           2  \n",
       "99464  0.0098           9             0        12           0  \n",
       "94750  0.0269           3             0        12           0  \n",
       "5535   0.1807           7             7         1           1  \n",
       "88952  0.0073           0             0         0           0  \n",
       "24848  0.0586          10            10         3           3  \n",
       "68995  0.0220           0             0         0           0  \n",
       "47912  0.0024           0             0         0           0  \n",
       "70771  0.0171           0             0         0           0  \n",
       "40754  0.1025           9             9         5           5  \n",
       "61900  0.0317           4             4         8           8  \n",
       "11175  0.0024           0             0         0           0  \n",
       "4765   0.2319           6             6         1           1  \n",
       "13957  0.9546           7             7         2           2  \n",
       "75051  0.0024          10             0         9           0  \n",
       "36380  0.0049           0             0         0           0  \n",
       "45209  0.0024           4             0         6           0  \n",
       "64968  0.0220           8             0         8           0  \n",
       "76502  0.0049           0             0         0           0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_excel('Dataset1 .xlsx')\n",
    "raw_data.sample(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cad9bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101014, 14)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d05a18f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['emg1', 'emg2', 'emg3', 'emg4', 'emg5', 'emg6', 'emg7', 'emg8', 'emg9',\n",
       "       'emg10', 'repetition', 'rerepetition', 'stimulus', 'restimulus'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "259f05e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101014 entries, 0 to 101013\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   emg1          101014 non-null  float64\n",
      " 1   emg2          101014 non-null  float64\n",
      " 2   emg3          101014 non-null  float64\n",
      " 3   emg4          101014 non-null  float64\n",
      " 4   emg5          101014 non-null  float64\n",
      " 5   emg6          101014 non-null  float64\n",
      " 6   emg7          101014 non-null  float64\n",
      " 7   emg8          101014 non-null  float64\n",
      " 8   emg9          101014 non-null  float64\n",
      " 9   emg10         101014 non-null  float64\n",
      " 10  repetition    101014 non-null  int64  \n",
      " 11  rerepetition  101014 non-null  int64  \n",
      " 12  stimulus      101014 non-null  int64  \n",
      " 13  restimulus    101014 non-null  int64  \n",
      "dtypes: float64(10), int64(4)\n",
      "memory usage: 10.8 MB\n"
     ]
    }
   ],
   "source": [
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "613a1cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emg1</th>\n",
       "      <th>emg2</th>\n",
       "      <th>emg3</th>\n",
       "      <th>emg4</th>\n",
       "      <th>emg5</th>\n",
       "      <th>emg6</th>\n",
       "      <th>emg7</th>\n",
       "      <th>emg8</th>\n",
       "      <th>emg9</th>\n",
       "      <th>emg10</th>\n",
       "      <th>repetition</th>\n",
       "      <th>rerepetition</th>\n",
       "      <th>stimulus</th>\n",
       "      <th>restimulus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>101014.000000</td>\n",
       "      <td>101014.000000</td>\n",
       "      <td>101014.000000</td>\n",
       "      <td>101014.000000</td>\n",
       "      <td>101014.000000</td>\n",
       "      <td>101014.000000</td>\n",
       "      <td>101014.000000</td>\n",
       "      <td>101014.000000</td>\n",
       "      <td>101014.000000</td>\n",
       "      <td>101014.000000</td>\n",
       "      <td>101014.000000</td>\n",
       "      <td>101014.000000</td>\n",
       "      <td>101014.000000</td>\n",
       "      <td>101014.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.039693</td>\n",
       "      <td>0.086158</td>\n",
       "      <td>0.041308</td>\n",
       "      <td>0.012502</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.005367</td>\n",
       "      <td>0.167648</td>\n",
       "      <td>0.116476</td>\n",
       "      <td>0.073460</td>\n",
       "      <td>0.054120</td>\n",
       "      <td>3.372948</td>\n",
       "      <td>2.055349</td>\n",
       "      <td>3.985665</td>\n",
       "      <td>2.329905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.127180</td>\n",
       "      <td>0.231539</td>\n",
       "      <td>0.101912</td>\n",
       "      <td>0.031334</td>\n",
       "      <td>0.009796</td>\n",
       "      <td>0.021238</td>\n",
       "      <td>0.403823</td>\n",
       "      <td>0.174862</td>\n",
       "      <td>0.156381</td>\n",
       "      <td>0.112567</td>\n",
       "      <td>3.497555</td>\n",
       "      <td>3.188164</td>\n",
       "      <td>4.162080</td>\n",
       "      <td>3.691976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.039100</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.046400</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.017100</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.024400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.129400</td>\n",
       "      <td>0.109900</td>\n",
       "      <td>0.068400</td>\n",
       "      <td>0.048800</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.399900</td>\n",
       "      <td>2.480500</td>\n",
       "      <td>1.340300</td>\n",
       "      <td>0.446800</td>\n",
       "      <td>0.293000</td>\n",
       "      <td>0.639600</td>\n",
       "      <td>4.660600</td>\n",
       "      <td>3.000500</td>\n",
       "      <td>1.752900</td>\n",
       "      <td>1.599100</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                emg1           emg2           emg3           emg4  \\\n",
       "count  101014.000000  101014.000000  101014.000000  101014.000000   \n",
       "mean        0.039693       0.086158       0.041308       0.012502   \n",
       "std         0.127180       0.231539       0.101912       0.031334   \n",
       "min         0.002400       0.000000       0.002400       0.000000   \n",
       "25%         0.002400       0.002400       0.002400       0.002400   \n",
       "50%         0.002400       0.002400       0.002400       0.002400   \n",
       "75%         0.024400       0.002400       0.012200       0.002400   \n",
       "max         2.399900       2.480500       1.340300       0.446800   \n",
       "\n",
       "                emg5           emg6           emg7           emg8  \\\n",
       "count  101014.000000  101014.000000  101014.000000  101014.000000   \n",
       "mean        0.003868       0.005367       0.167648       0.116476   \n",
       "std         0.009796       0.021238       0.403823       0.174862   \n",
       "min         0.002400       0.000000       0.002400       0.002400   \n",
       "25%         0.002400       0.002400       0.009800       0.039100   \n",
       "50%         0.002400       0.002400       0.046400       0.061000   \n",
       "75%         0.002400       0.002400       0.129400       0.109900   \n",
       "max         0.293000       0.639600       4.660600       3.000500   \n",
       "\n",
       "                emg9          emg10     repetition   rerepetition  \\\n",
       "count  101014.000000  101014.000000  101014.000000  101014.000000   \n",
       "mean        0.073460       0.054120       3.372948       2.055349   \n",
       "std         0.156381       0.112567       3.497555       3.188164   \n",
       "min         0.000000       0.002400       0.000000       0.000000   \n",
       "25%         0.002400       0.004900       0.000000       0.000000   \n",
       "50%         0.002400       0.017100       2.000000       0.000000   \n",
       "75%         0.068400       0.048800       6.000000       4.000000   \n",
       "max         1.752900       1.599100      10.000000      10.000000   \n",
       "\n",
       "            stimulus     restimulus  \n",
       "count  101014.000000  101014.000000  \n",
       "mean        3.985665       2.329905  \n",
       "std         4.162080       3.691976  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.000000       0.000000  \n",
       "50%         3.000000       0.000000  \n",
       "75%         8.000000       4.000000  \n",
       "max        12.000000      12.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd128768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Dependent values and their counts :\n",
      "0     39063\n",
      "2      5174\n",
      "4      5173\n",
      "5      5173\n",
      "12     5173\n",
      "8      5172\n",
      "7      5171\n",
      "6      5170\n",
      "11     5166\n",
      "3      5158\n",
      "1      5149\n",
      "10     5137\n",
      "9      5135\n",
      "Name: stimulus, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique Dependent values and their counts :\")\n",
    "print(raw_data[\"stimulus\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93de5c20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_classes = pd.value_counts(raw_data['stimulus'], sort = True)\n",
    "\n",
    "count_classes.plot(kind = 'bar', rot=0)\n",
    "\n",
    "plt.title(\"stimulus Class Distribution\")\n",
    "\n",
    "plt.xlabel(\"Class\")\n",
    "\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359a141d",
   "metadata": {},
   "source": [
    "# Data Cleaning and Exploratory Data Analysis with New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34a50c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          emg1    emg2    emg3    emg4    emg5    emg6    emg7    emg8  \\\n",
      "0       0.0684  0.0024  0.0024  0.0024  0.0024  0.0098  0.0024  0.0488   \n",
      "1       0.0586  0.0024  0.0024  0.0024  0.0024  0.0049  0.0024  0.0415   \n",
      "2       0.0562  0.0024  0.0024  0.0024  0.0024  0.0049  0.0024  0.0391   \n",
      "3       0.0562  0.0024  0.0024  0.0024  0.0024  0.0049  0.0024  0.0342   \n",
      "4       0.0488  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0366   \n",
      "...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "101009  0.0024  0.0024  0.0024  0.0024  0.0049  0.0024  0.0024  0.0366   \n",
      "101010  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0342   \n",
      "101011  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0342   \n",
      "101012  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0366   \n",
      "101013  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0391   \n",
      "\n",
      "          emg9   emg10  repetition  rerepetition  stimulus  restimulus  \n",
      "0       0.0024  0.0342           0             0         0           0  \n",
      "1       0.0024  0.0293           0             0         0           0  \n",
      "2       0.0024  0.0244           0             0         0           0  \n",
      "3       0.0024  0.0171           0             0         0           0  \n",
      "4       0.0024  0.0146           0             0         0           0  \n",
      "...        ...     ...         ...           ...       ...         ...  \n",
      "101009  0.0024  0.0024           0             0         0           0  \n",
      "101010  0.0024  0.0024           0             0         0           0  \n",
      "101011  0.0024  0.0073           0             0         0           0  \n",
      "101012  0.0024  0.0073           0             0         0           0  \n",
      "101013  0.0024  0.0024           0             0         0           0  \n",
      "\n",
      "[75043 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "index_names = raw_data[ (raw_data['stimulus'] != raw_data['restimulus'])].index\n",
    "raw_data.drop(index_names, inplace = True)\n",
    "print(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78d479cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          emg1    emg2    emg3    emg4    emg5    emg6    emg7    emg8  \\\n",
      "0       0.0684  0.0024  0.0024  0.0024  0.0024  0.0098  0.0024  0.0488   \n",
      "1       0.0586  0.0024  0.0024  0.0024  0.0024  0.0049  0.0024  0.0415   \n",
      "2       0.0562  0.0024  0.0024  0.0024  0.0024  0.0049  0.0024  0.0391   \n",
      "3       0.0562  0.0024  0.0024  0.0024  0.0024  0.0049  0.0024  0.0342   \n",
      "4       0.0488  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0366   \n",
      "...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "101009  0.0024  0.0024  0.0024  0.0024  0.0049  0.0024  0.0024  0.0366   \n",
      "101010  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0342   \n",
      "101011  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0342   \n",
      "101012  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0366   \n",
      "101013  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0391   \n",
      "\n",
      "          emg9   emg10  repetition  rerepetition  stimulus  restimulus  \n",
      "0       0.0024  0.0342           0             0         0           0  \n",
      "1       0.0024  0.0293           0             0         0           0  \n",
      "2       0.0024  0.0244           0             0         0           0  \n",
      "3       0.0024  0.0171           0             0         0           0  \n",
      "4       0.0024  0.0146           0             0         0           0  \n",
      "...        ...     ...         ...           ...       ...         ...  \n",
      "101009  0.0024  0.0024           0             0         0           0  \n",
      "101010  0.0024  0.0024           0             0         0           0  \n",
      "101011  0.0024  0.0073           0             0         0           0  \n",
      "101012  0.0024  0.0073           0             0         0           0  \n",
      "101013  0.0024  0.0024           0             0         0           0  \n",
      "\n",
      "[75043 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "index_names = raw_data[ (raw_data['repetition'] != raw_data['rerepetition'])].index\n",
    "raw_data.drop(index_names, inplace = True)\n",
    "print(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8418d307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emg1</th>\n",
       "      <th>emg2</th>\n",
       "      <th>emg3</th>\n",
       "      <th>emg4</th>\n",
       "      <th>emg5</th>\n",
       "      <th>emg6</th>\n",
       "      <th>emg7</th>\n",
       "      <th>emg8</th>\n",
       "      <th>emg9</th>\n",
       "      <th>emg10</th>\n",
       "      <th>repetition</th>\n",
       "      <th>rerepetition</th>\n",
       "      <th>stimulus</th>\n",
       "      <th>restimulus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57703</th>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.2612</td>\n",
       "      <td>0.0439</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.8154</td>\n",
       "      <td>0.2295</td>\n",
       "      <td>0.1563</td>\n",
       "      <td>0.3223</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42472</th>\n",
       "      <td>0.0854</td>\n",
       "      <td>0.2612</td>\n",
       "      <td>0.2246</td>\n",
       "      <td>0.0757</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0269</td>\n",
       "      <td>1.0278</td>\n",
       "      <td>0.3003</td>\n",
       "      <td>0.2905</td>\n",
       "      <td>0.1782</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81681</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81680</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0488</td>\n",
       "      <td>0.0439</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83637</th>\n",
       "      <td>0.0488</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0342</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.1221</td>\n",
       "      <td>0.0635</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44344</th>\n",
       "      <td>0.0513</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0684</td>\n",
       "      <td>0.1709</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.1440</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0269</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91625</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0513</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87798</th>\n",
       "      <td>0.1025</td>\n",
       "      <td>0.3857</td>\n",
       "      <td>0.0391</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.1855</td>\n",
       "      <td>0.6152</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>0.4346</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27861</th>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.0537</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77468</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0513</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77601</th>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0684</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34444</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0317</td>\n",
       "      <td>0.0903</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0220</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19732</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0757</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14571</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7847</th>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0269</td>\n",
       "      <td>0.0415</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17858</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35029</th>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0732</td>\n",
       "      <td>0.0537</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.2222</td>\n",
       "      <td>0.1318</td>\n",
       "      <td>0.1025</td>\n",
       "      <td>0.0391</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50503</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0537</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68095</th>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0781</td>\n",
       "      <td>0.1294</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0269</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66373</th>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0342</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         emg1    emg2    emg3    emg4    emg5    emg6    emg7    emg8    emg9  \\\n",
       "57703  0.3613  0.2612  0.0439  0.0146  0.0024  0.0024  0.8154  0.2295  0.1563   \n",
       "42472  0.0854  0.2612  0.2246  0.0757  0.0024  0.0269  1.0278  0.3003  0.2905   \n",
       "81681  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0464  0.0464  0.0024   \n",
       "81680  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0488  0.0439  0.0024   \n",
       "83637  0.0488  0.0024  0.0342  0.0024  0.0024  0.0024  0.1221  0.0635  0.0024   \n",
       "44344  0.0513  0.0024  0.0684  0.1709  0.0024  0.0024  0.0098  0.1440  0.0024   \n",
       "91625  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0122  0.0513  0.0024   \n",
       "87798  0.1025  0.3857  0.0391  0.0024  0.0024  0.0024  0.1855  0.6152  0.1147   \n",
       "27861  0.0049  0.0024  0.0024  0.0024  0.0024  0.0024  0.0195  0.0537  0.0024   \n",
       "77468  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0122  0.0513  0.0024   \n",
       "77601  0.0220  0.0024  0.0024  0.0024  0.0024  0.0024  0.0244  0.0684  0.0024   \n",
       "34444  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0317  0.0903  0.0024   \n",
       "19732  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0049  0.0757  0.0122   \n",
       "14571  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0195  0.0024   \n",
       "7847   0.0073  0.0024  0.0024  0.0024  0.0024  0.0024  0.0269  0.0415  0.0024   \n",
       "17858  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0244  0.0024   \n",
       "35029  0.0464  0.0024  0.0732  0.0537  0.0024  0.0024  0.2222  0.1318  0.1025   \n",
       "50503  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0024  0.0537  0.0024   \n",
       "68095  0.0049  0.0024  0.0024  0.0024  0.0024  0.0024  0.0781  0.1294  0.0024   \n",
       "66373  0.0073  0.0024  0.0024  0.0024  0.0024  0.0024  0.0464  0.0244  0.0024   \n",
       "\n",
       "        emg10  repetition  rerepetition  stimulus  restimulus  \n",
       "57703  0.3223           9             9         7           7  \n",
       "42472  0.1782           1             1         6           6  \n",
       "81681  0.0024           0             0         0           0  \n",
       "81680  0.0024           0             0         0           0  \n",
       "83637  0.0049          10            10        10          10  \n",
       "44344  0.0269           3             3         6           6  \n",
       "91625  0.0049           0             0         0           0  \n",
       "87798  0.4346           5             5        11          11  \n",
       "27861  0.0098           0             0         0           0  \n",
       "77468  0.0024           0             0         0           0  \n",
       "77601  0.0073           3             3        10          10  \n",
       "34444  0.0220           0             0         0           0  \n",
       "19732  0.0024           4             4         3           3  \n",
       "14571  0.0024           0             0         0           0  \n",
       "7847   0.0024           0             0         0           0  \n",
       "17858  0.0049           0             0         0           0  \n",
       "35029  0.0391           2             2         5           5  \n",
       "50503  0.0024           0             0         0           0  \n",
       "68095  0.0269           0             0         0           0  \n",
       "66373  0.0342           0             0         0           0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff5d7709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75043, 14)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9df2c3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 75043 entries, 0 to 101013\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   emg1          75043 non-null  float64\n",
      " 1   emg2          75043 non-null  float64\n",
      " 2   emg3          75043 non-null  float64\n",
      " 3   emg4          75043 non-null  float64\n",
      " 4   emg5          75043 non-null  float64\n",
      " 5   emg6          75043 non-null  float64\n",
      " 6   emg7          75043 non-null  float64\n",
      " 7   emg8          75043 non-null  float64\n",
      " 8   emg9          75043 non-null  float64\n",
      " 9   emg10         75043 non-null  float64\n",
      " 10  repetition    75043 non-null  int64  \n",
      " 11  rerepetition  75043 non-null  int64  \n",
      " 12  stimulus      75043 non-null  int64  \n",
      " 13  restimulus    75043 non-null  int64  \n",
      "dtypes: float64(10), int64(4)\n",
      "memory usage: 10.6 MB\n"
     ]
    }
   ],
   "source": [
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbec9c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emg1            False\n",
      "emg2            False\n",
      "emg3            False\n",
      "emg4            False\n",
      "emg5            False\n",
      "emg6            False\n",
      "emg7            False\n",
      "emg8            False\n",
      "emg9            False\n",
      "emg10           False\n",
      "repetition      False\n",
      "rerepetition    False\n",
      "stimulus        False\n",
      "restimulus      False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(raw_data.isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a406dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = raw_data.iloc[:,0:10]\n",
    "y = raw_data.stimulus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "867f6716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 39)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8924265",
   "metadata": {},
   "source": [
    "# Importing Libraries of Deeplearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e21b1294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.constraints import maxnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a5751d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1facbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding for categorical labels\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9451ac57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take a subset of train for grid search. Let us take 10% for now\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_grid, x_not_use, y_grid, y_not_use = train_test_split(X_train, y_train, test_size=0.9, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9b88b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "input_dim = x_grid.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc254e8f",
   "metadata": {},
   "source": [
    "# Model Architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9fde1b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: Add default optimizer, otherwise throws error 'optimizer not legal parameter'\n",
    "def define_model(dropout_rate=0.0, weight_constraint=0, neurons=10):   \n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, activation='relu', kernel_initializer='he_uniform', \n",
    "                    input_dim = input_dim, kernel_constraint=maxnorm(weight_constraint))) \n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neurons, kernel_initializer='he_uniform', activation='relu'))\n",
    "    model.add(Dense(num_classes, kernel_initializer='he_uniform', activation='softmax'))\n",
    "    \n",
    "    # compile the model\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='Adam',      \n",
    "                  metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "192a8df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 2.2696 - acc: 0.5207\n",
      "Epoch 2/10\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 1.4134 - acc: 0.6360\n",
      "Epoch 3/10\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 1.1045 - acc: 0.7075\n",
      "Epoch 4/10\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.9858 - acc: 0.7330\n",
      "Epoch 5/10\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.9138 - acc: 0.7530\n",
      "Epoch 6/10\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.8652 - acc: 0.7625\n",
      "Epoch 7/10\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.8284 - acc: 0.7673\n",
      "Epoch 8/10\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.7992 - acc: 0.7758\n",
      "Epoch 9/10\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.7754 - acc: 0.7804\n",
      "Epoch 10/10\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.7574 - acc: 0.7844\n"
     ]
    }
   ],
   "source": [
    "# implement the Scikit-Learn classifier interface\n",
    "# requires model defined as a function, which we already have\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "model = KerasClassifier(build_fn=define_model, \n",
    "                        verbose=1)\n",
    "\n",
    "dropout_rate = [0.0, 0.2, 0.4]\n",
    "weight_constraint = [1, 2, 3]\n",
    "neurons = [10, 32, 64]\n",
    "batch_size = [100, 200, 400]\n",
    "epochs = [1, 5, 10]\n",
    "\n",
    "param_grid = dict(dropout_rate=dropout_rate, \n",
    "                  weight_constraint=weight_constraint,\n",
    "                  neurons=neurons, batch_size=batch_size, \n",
    "                  epochs=epochs)\n",
    "\n",
    "#n_jobs=16 uses 16 CPUs. Try not to do -1 on your system as it may hang!!!\n",
    "# -1 refers to using all available CPUs\n",
    "#Cross validation, cv=3\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=16, cv=3)\n",
    "\n",
    "grid_result = grid.fit(x_grid, y_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4405438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.771448 using {'batch_size': 100, 'dropout_rate': 0.0, 'epochs': 10, 'neurons': 64, 'weight_constraint': 2}\n",
      "Mean = 0.523405 (std=0.011428) with: {'batch_size': 100, 'dropout_rate': 0.0, 'epochs': 1, 'neurons': 10, 'weight_constraint': 1}\n",
      "Mean = 0.524071 (std=0.014254) with: {'batch_size': 100, 'dropout_rate': 0.0, 'epochs': 1, 'neurons': 10, 'weight_constraint': 2}\n",
      "Mean = 0.514909 (std=0.005388) with: {'batch_size': 100, 'dropout_rate': 0.0, 'epochs': 1, 'neurons': 10, 'weight_constraint': 3}\n",
      "Mean = 0.546060 (std=0.014219) with: {'batch_size': 100, 'dropout_rate': 0.0, 'epochs': 1, 'neurons': 32, 'weight_constraint': 1}\n",
      "Mean = 0.540896 (std=0.015721) with: {'batch_size': 100, 'dropout_rate': 0.0, 'epochs': 1, 'neurons': 32, 'weight_constraint': 2}\n",
      "Mean = 0.579544 (std=0.024114) with: {'batch_size': 100, 'dropout_rate': 0.0, 'epochs': 1, 'neurons': 32, 'weight_constraint': 3}\n",
      "Mean = 0.585207 (std=0.014690) with: {'batch_size': 100, 'dropout_rate': 0.0, 'epochs': 1, 'neurons': 64, 'weight_constraint': 1}\n",
      "Mean = 0.581043 (std=0.032578) with: {'batch_size': 100, 'dropout_rate': 0.0, 'epochs': 1, 'neurons': 64, 'weight_constraint': 2}\n",
      "Mean = 0.591371 (std=0.030389) with: {'batch_size': 100, 'dropout_rate': 0.0, 'epochs': 1, 'neurons': 64, 'weight_constraint': 3}\n",
      "Mean = 0.529735 (std=0.016429) with: {'batch_size': 100, 'dropout_rate': 0.0, 'epochs': 5, 'neurons': 10, 'weight_constraint': 1}\n",
      "Mean = 0.522239 (std=0.028376) with: {'batch_size': 100, 'dropout_rate': 0.0, 'epochs': 5, 'neurons': 10, 'weight_constraint': 2}\n",
      "Mean = 0.543895 (std=0.010533) with: {'batch_size': 100, 'dropout_rate': 0.0, 'epochs': 5, 'neurons': 10, 'weight_constraint': 3}\n",
      "Mean = 0.647676 (std=0.019411) with: {'batch_size': 100, 'dropout_rate': 0.0, 'epochs': 5, 'neurons': 32, 'weight_constraint': 1}\n",
      "Mean = 0.681659 (std=0.006161) with: {'batch_size': 100, 'dropout_rate': 0.0, 'epochs': 5, 'neurons': 32, 'weight_constraint': 2}\n",
      "Mean = 0.650008 (std=0.007257) with: {'batch_size': 100, 'dropout_rate': 0.0, 'epochs': 5, 'neurons': 32, 'weight_constraint': 3}\n",
      "Mean = 0.719474 (std=0.005732) with: {'batch_size': 100, 'dropout_rate': 0.0, 'epochs': 5, 'neurons': 64, 'weight_constraint': 1}\n",
      "Mean = 0.735632 (std=0.005096) with: {'batch_size': 100, 'dropout_rate': 0.0, 'epochs': 5, 'neurons': 64, 'weight_constraint': 2}\n",
      "Mean = 0.731134 (std=0.006011) with: {'batch_size': 100, 'dropout_rate': 0.0, 'epochs': 5, 'neurons': 64, 'weight_constraint': 3}\n",
      "Mean = 0.568549 (std=0.028808) with: {'batch_size': 100, 'dropout_rate': 0.0, 'epochs': 10, 'neurons': 10, 'weight_constraint': 1}\n",
      "Mean = 0.602532 (std=0.007303) with: {'batch_size': 100, 'dropout_rate': 0.0, 'epochs': 10, 'neurons': 10, 'weight_constraint': 2}\n",
      "Mean = 0.594536 (std=0.012175) with: {'batch_size': 100, 'dropout_rate': 0.0, 'epochs': 10, 'neurons': 10, 'weight_constraint': 3}\n",
      "Mean = 0.701483 (std=0.013731) with: {'batch_size': 100, 'dropout_rate': 0.0, 'epochs': 10, 'neurons': 32, 'weight_constraint': 1}\n",
      "Mean = 0.726470 (std=0.011608) with: {'batch_size': 100, 'dropout_rate': 0.0, 'epochs': 10, 'neurons': 32, 'weight_constraint': 2}\n",
      "Mean = 0.729968 (std=0.004902) with: {'batch_size': 100, 'dropout_rate': 0.0, 'epochs': 10, 'neurons': 32, 'weight_constraint': 3}\n",
      "Mean = 0.758288 (std=0.002717) with: {'batch_size': 100, 'dropout_rate': 0.0, 'epochs': 10, 'neurons': 64, 'weight_constraint': 1}\n",
      "Mean = 0.771448 (std=0.002895) with: {'batch_size': 100, 'dropout_rate': 0.0, 'epochs': 10, 'neurons': 64, 'weight_constraint': 2}\n",
      "Mean = 0.757288 (std=0.006783) with: {'batch_size': 100, 'dropout_rate': 0.0, 'epochs': 10, 'neurons': 64, 'weight_constraint': 3}\n",
      "Mean = 0.519574 (std=0.020379) with: {'batch_size': 100, 'dropout_rate': 0.2, 'epochs': 1, 'neurons': 10, 'weight_constraint': 1}\n",
      "Mean = 0.520573 (std=0.029713) with: {'batch_size': 100, 'dropout_rate': 0.2, 'epochs': 1, 'neurons': 10, 'weight_constraint': 2}\n",
      "Mean = 0.524738 (std=0.007356) with: {'batch_size': 100, 'dropout_rate': 0.2, 'epochs': 1, 'neurons': 10, 'weight_constraint': 3}\n",
      "Mean = 0.540230 (std=0.004811) with: {'batch_size': 100, 'dropout_rate': 0.2, 'epochs': 1, 'neurons': 32, 'weight_constraint': 1}\n",
      "Mean = 0.545227 (std=0.012748) with: {'batch_size': 100, 'dropout_rate': 0.2, 'epochs': 1, 'neurons': 32, 'weight_constraint': 2}\n",
      "Mean = 0.538231 (std=0.019522) with: {'batch_size': 100, 'dropout_rate': 0.2, 'epochs': 1, 'neurons': 32, 'weight_constraint': 3}\n",
      "Mean = 0.581543 (std=0.011572) with: {'batch_size': 100, 'dropout_rate': 0.2, 'epochs': 1, 'neurons': 64, 'weight_constraint': 1}\n",
      "Mean = 0.582042 (std=0.005540) with: {'batch_size': 100, 'dropout_rate': 0.2, 'epochs': 1, 'neurons': 64, 'weight_constraint': 2}\n",
      "Mean = 0.584208 (std=0.010554) with: {'batch_size': 100, 'dropout_rate': 0.2, 'epochs': 1, 'neurons': 64, 'weight_constraint': 3}\n",
      "Mean = 0.535899 (std=0.013899) with: {'batch_size': 100, 'dropout_rate': 0.2, 'epochs': 5, 'neurons': 10, 'weight_constraint': 1}\n",
      "Mean = 0.521739 (std=0.018783) with: {'batch_size': 100, 'dropout_rate': 0.2, 'epochs': 5, 'neurons': 10, 'weight_constraint': 2}\n",
      "Mean = 0.544394 (std=0.020029) with: {'batch_size': 100, 'dropout_rate': 0.2, 'epochs': 5, 'neurons': 10, 'weight_constraint': 3}\n",
      "Mean = 0.644678 (std=0.013855) with: {'batch_size': 100, 'dropout_rate': 0.2, 'epochs': 5, 'neurons': 32, 'weight_constraint': 1}\n",
      "Mean = 0.656838 (std=0.017052) with: {'batch_size': 100, 'dropout_rate': 0.2, 'epochs': 5, 'neurons': 32, 'weight_constraint': 2}\n",
      "Mean = 0.644511 (std=0.012419) with: {'batch_size': 100, 'dropout_rate': 0.2, 'epochs': 5, 'neurons': 32, 'weight_constraint': 3}\n",
      "Mean = 0.713310 (std=0.004401) with: {'batch_size': 100, 'dropout_rate': 0.2, 'epochs': 5, 'neurons': 64, 'weight_constraint': 1}\n",
      "Mean = 0.723472 (std=0.013670) with: {'batch_size': 100, 'dropout_rate': 0.2, 'epochs': 5, 'neurons': 64, 'weight_constraint': 2}\n",
      "Mean = 0.726470 (std=0.004712) with: {'batch_size': 100, 'dropout_rate': 0.2, 'epochs': 5, 'neurons': 64, 'weight_constraint': 3}\n",
      "Mean = 0.547060 (std=0.025685) with: {'batch_size': 100, 'dropout_rate': 0.2, 'epochs': 10, 'neurons': 10, 'weight_constraint': 1}\n",
      "Mean = 0.573880 (std=0.012486) with: {'batch_size': 100, 'dropout_rate': 0.2, 'epochs': 10, 'neurons': 10, 'weight_constraint': 2}\n",
      "Mean = 0.570048 (std=0.029227) with: {'batch_size': 100, 'dropout_rate': 0.2, 'epochs': 10, 'neurons': 10, 'weight_constraint': 3}\n",
      "Mean = 0.700483 (std=0.004247) with: {'batch_size': 100, 'dropout_rate': 0.2, 'epochs': 10, 'neurons': 32, 'weight_constraint': 1}\n",
      "Mean = 0.724471 (std=0.007405) with: {'batch_size': 100, 'dropout_rate': 0.2, 'epochs': 10, 'neurons': 32, 'weight_constraint': 2}\n",
      "Mean = 0.723472 (std=0.005134) with: {'batch_size': 100, 'dropout_rate': 0.2, 'epochs': 10, 'neurons': 32, 'weight_constraint': 3}\n",
      "Mean = 0.749792 (std=0.006734) with: {'batch_size': 100, 'dropout_rate': 0.2, 'epochs': 10, 'neurons': 64, 'weight_constraint': 1}\n",
      "Mean = 0.759953 (std=0.001247) with: {'batch_size': 100, 'dropout_rate': 0.2, 'epochs': 10, 'neurons': 64, 'weight_constraint': 2}\n",
      "Mean = 0.765284 (std=0.003008) with: {'batch_size': 100, 'dropout_rate': 0.2, 'epochs': 10, 'neurons': 64, 'weight_constraint': 3}\n",
      "Mean = 0.500416 (std=0.025917) with: {'batch_size': 100, 'dropout_rate': 0.4, 'epochs': 1, 'neurons': 10, 'weight_constraint': 1}\n",
      "Mean = 0.512577 (std=0.018177) with: {'batch_size': 100, 'dropout_rate': 0.4, 'epochs': 1, 'neurons': 10, 'weight_constraint': 2}\n",
      "Mean = 0.515909 (std=0.011140) with: {'batch_size': 100, 'dropout_rate': 0.4, 'epochs': 1, 'neurons': 10, 'weight_constraint': 3}\n",
      "Mean = 0.533567 (std=0.016526) with: {'batch_size': 100, 'dropout_rate': 0.4, 'epochs': 1, 'neurons': 32, 'weight_constraint': 1}\n",
      "Mean = 0.545227 (std=0.028563) with: {'batch_size': 100, 'dropout_rate': 0.4, 'epochs': 1, 'neurons': 32, 'weight_constraint': 2}\n",
      "Mean = 0.521406 (std=0.021030) with: {'batch_size': 100, 'dropout_rate': 0.4, 'epochs': 1, 'neurons': 32, 'weight_constraint': 3}\n",
      "Mean = 0.551724 (std=0.019385) with: {'batch_size': 100, 'dropout_rate': 0.4, 'epochs': 1, 'neurons': 64, 'weight_constraint': 1}\n",
      "Mean = 0.562385 (std=0.008989) with: {'batch_size': 100, 'dropout_rate': 0.4, 'epochs': 1, 'neurons': 64, 'weight_constraint': 2}\n",
      "Mean = 0.541729 (std=0.015306) with: {'batch_size': 100, 'dropout_rate': 0.4, 'epochs': 1, 'neurons': 64, 'weight_constraint': 3}\n",
      "Mean = 0.534566 (std=0.006941) with: {'batch_size': 100, 'dropout_rate': 0.4, 'epochs': 5, 'neurons': 10, 'weight_constraint': 1}\n",
      "Mean = 0.521573 (std=0.005102) with: {'batch_size': 100, 'dropout_rate': 0.4, 'epochs': 5, 'neurons': 10, 'weight_constraint': 2}\n",
      "Mean = 0.529402 (std=0.008376) with: {'batch_size': 100, 'dropout_rate': 0.4, 'epochs': 5, 'neurons': 10, 'weight_constraint': 3}\n",
      "Mean = 0.626354 (std=0.012250) with: {'batch_size': 100, 'dropout_rate': 0.4, 'epochs': 5, 'neurons': 32, 'weight_constraint': 1}\n",
      "Mean = 0.645011 (std=0.006404) with: {'batch_size': 100, 'dropout_rate': 0.4, 'epochs': 5, 'neurons': 32, 'weight_constraint': 2}\n",
      "Mean = 0.636348 (std=0.010438) with: {'batch_size': 100, 'dropout_rate': 0.4, 'epochs': 5, 'neurons': 32, 'weight_constraint': 3}\n",
      "Mean = 0.694986 (std=0.004108) with: {'batch_size': 100, 'dropout_rate': 0.4, 'epochs': 5, 'neurons': 64, 'weight_constraint': 1}\n",
      "Mean = 0.721972 (std=0.005790) with: {'batch_size': 100, 'dropout_rate': 0.4, 'epochs': 5, 'neurons': 64, 'weight_constraint': 2}\n",
      "Mean = 0.709645 (std=0.003740) with: {'batch_size': 100, 'dropout_rate': 0.4, 'epochs': 5, 'neurons': 64, 'weight_constraint': 3}\n",
      "Mean = 0.555889 (std=0.022104) with: {'batch_size': 100, 'dropout_rate': 0.4, 'epochs': 10, 'neurons': 10, 'weight_constraint': 1}\n",
      "Mean = 0.558387 (std=0.033052) with: {'batch_size': 100, 'dropout_rate': 0.4, 'epochs': 10, 'neurons': 10, 'weight_constraint': 2}\n",
      "Mean = 0.555556 (std=0.013971) with: {'batch_size': 100, 'dropout_rate': 0.4, 'epochs': 10, 'neurons': 10, 'weight_constraint': 3}\n",
      "Mean = 0.682492 (std=0.011843) with: {'batch_size': 100, 'dropout_rate': 0.4, 'epochs': 10, 'neurons': 32, 'weight_constraint': 1}\n",
      "Mean = 0.698817 (std=0.007130) with: {'batch_size': 100, 'dropout_rate': 0.4, 'epochs': 10, 'neurons': 32, 'weight_constraint': 2}\n",
      "Mean = 0.704814 (std=0.010334) with: {'batch_size': 100, 'dropout_rate': 0.4, 'epochs': 10, 'neurons': 32, 'weight_constraint': 3}\n",
      "Mean = 0.736299 (std=0.004586) with: {'batch_size': 100, 'dropout_rate': 0.4, 'epochs': 10, 'neurons': 64, 'weight_constraint': 1}\n",
      "Mean = 0.755289 (std=0.004495) with: {'batch_size': 100, 'dropout_rate': 0.4, 'epochs': 10, 'neurons': 64, 'weight_constraint': 2}\n",
      "Mean = 0.752291 (std=0.005199) with: {'batch_size': 100, 'dropout_rate': 0.4, 'epochs': 10, 'neurons': 64, 'weight_constraint': 3}\n",
      "Mean = 0.507080 (std=0.027561) with: {'batch_size': 200, 'dropout_rate': 0.0, 'epochs': 1, 'neurons': 10, 'weight_constraint': 1}\n",
      "Mean = 0.502749 (std=0.011663) with: {'batch_size': 200, 'dropout_rate': 0.0, 'epochs': 1, 'neurons': 10, 'weight_constraint': 2}\n",
      "Mean = 0.487590 (std=0.036684) with: {'batch_size': 200, 'dropout_rate': 0.0, 'epochs': 1, 'neurons': 10, 'weight_constraint': 3}\n",
      "Mean = 0.544894 (std=0.033460) with: {'batch_size': 200, 'dropout_rate': 0.0, 'epochs': 1, 'neurons': 32, 'weight_constraint': 1}\n",
      "Mean = 0.539564 (std=0.021674) with: {'batch_size': 200, 'dropout_rate': 0.0, 'epochs': 1, 'neurons': 32, 'weight_constraint': 2}\n",
      "Mean = 0.507246 (std=0.057122) with: {'batch_size': 200, 'dropout_rate': 0.0, 'epochs': 1, 'neurons': 32, 'weight_constraint': 3}\n",
      "Mean = 0.548559 (std=0.029095) with: {'batch_size': 200, 'dropout_rate': 0.0, 'epochs': 1, 'neurons': 64, 'weight_constraint': 1}\n",
      "Mean = 0.570715 (std=0.023610) with: {'batch_size': 200, 'dropout_rate': 0.0, 'epochs': 1, 'neurons': 64, 'weight_constraint': 2}\n",
      "Mean = 0.566383 (std=0.023954) with: {'batch_size': 200, 'dropout_rate': 0.0, 'epochs': 1, 'neurons': 64, 'weight_constraint': 3}\n",
      "Mean = 0.523905 (std=0.024862) with: {'batch_size': 200, 'dropout_rate': 0.0, 'epochs': 5, 'neurons': 10, 'weight_constraint': 1}\n",
      "Mean = 0.521073 (std=0.022975) with: {'batch_size': 200, 'dropout_rate': 0.0, 'epochs': 5, 'neurons': 10, 'weight_constraint': 2}\n",
      "Mean = 0.528902 (std=0.008601) with: {'batch_size': 200, 'dropout_rate': 0.0, 'epochs': 5, 'neurons': 10, 'weight_constraint': 3}\n",
      "Mean = 0.584041 (std=0.011413) with: {'batch_size': 200, 'dropout_rate': 0.0, 'epochs': 5, 'neurons': 32, 'weight_constraint': 1}\n",
      "Mean = 0.568216 (std=0.033956) with: {'batch_size': 200, 'dropout_rate': 0.0, 'epochs': 5, 'neurons': 32, 'weight_constraint': 2}\n",
      "Mean = 0.596702 (std=0.012370) with: {'batch_size': 200, 'dropout_rate': 0.0, 'epochs': 5, 'neurons': 32, 'weight_constraint': 3}\n",
      "Mean = 0.657005 (std=0.010204) with: {'batch_size': 200, 'dropout_rate': 0.0, 'epochs': 5, 'neurons': 64, 'weight_constraint': 1}\n",
      "Mean = 0.671997 (std=0.017052) with: {'batch_size': 200, 'dropout_rate': 0.0, 'epochs': 5, 'neurons': 64, 'weight_constraint': 2}\n",
      "Mean = 0.668499 (std=0.003565) with: {'batch_size': 200, 'dropout_rate': 0.0, 'epochs': 5, 'neurons': 64, 'weight_constraint': 3}\n",
      "Mean = 0.528736 (std=0.021672) with: {'batch_size': 200, 'dropout_rate': 0.0, 'epochs': 10, 'neurons': 10, 'weight_constraint': 1}\n",
      "Mean = 0.532234 (std=0.030154) with: {'batch_size': 200, 'dropout_rate': 0.0, 'epochs': 10, 'neurons': 10, 'weight_constraint': 2}\n",
      "Mean = 0.543562 (std=0.010959) with: {'batch_size': 200, 'dropout_rate': 0.0, 'epochs': 10, 'neurons': 10, 'weight_constraint': 3}\n",
      "Mean = 0.644178 (std=0.010419) with: {'batch_size': 200, 'dropout_rate': 0.0, 'epochs': 10, 'neurons': 32, 'weight_constraint': 1}\n",
      "Mean = 0.642012 (std=0.014423) with: {'batch_size': 200, 'dropout_rate': 0.0, 'epochs': 10, 'neurons': 32, 'weight_constraint': 2}\n",
      "Mean = 0.669998 (std=0.006953) with: {'batch_size': 200, 'dropout_rate': 0.0, 'epochs': 10, 'neurons': 32, 'weight_constraint': 3}\n",
      "Mean = 0.715809 (std=0.010245) with: {'batch_size': 200, 'dropout_rate': 0.0, 'epochs': 10, 'neurons': 64, 'weight_constraint': 1}\n",
      "Mean = 0.736965 (std=0.005167) with: {'batch_size': 200, 'dropout_rate': 0.0, 'epochs': 10, 'neurons': 64, 'weight_constraint': 2}\n",
      "Mean = 0.734966 (std=0.004188) with: {'batch_size': 200, 'dropout_rate': 0.0, 'epochs': 10, 'neurons': 64, 'weight_constraint': 3}\n",
      "Mean = 0.513077 (std=0.020542) with: {'batch_size': 200, 'dropout_rate': 0.2, 'epochs': 1, 'neurons': 10, 'weight_constraint': 1}\n",
      "Mean = 0.483758 (std=0.038910) with: {'batch_size': 200, 'dropout_rate': 0.2, 'epochs': 1, 'neurons': 10, 'weight_constraint': 2}\n",
      "Mean = 0.493253 (std=0.038771) with: {'batch_size': 200, 'dropout_rate': 0.2, 'epochs': 1, 'neurons': 10, 'weight_constraint': 3}\n",
      "Mean = 0.544561 (std=0.032888) with: {'batch_size': 200, 'dropout_rate': 0.2, 'epochs': 1, 'neurons': 32, 'weight_constraint': 1}\n",
      "Mean = 0.511411 (std=0.030364) with: {'batch_size': 200, 'dropout_rate': 0.2, 'epochs': 1, 'neurons': 32, 'weight_constraint': 2}\n",
      "Mean = 0.532900 (std=0.018772) with: {'batch_size': 200, 'dropout_rate': 0.2, 'epochs': 1, 'neurons': 32, 'weight_constraint': 3}\n",
      "Mean = 0.566383 (std=0.014376) with: {'batch_size': 200, 'dropout_rate': 0.2, 'epochs': 1, 'neurons': 64, 'weight_constraint': 1}\n",
      "Mean = 0.592370 (std=0.009397) with: {'batch_size': 200, 'dropout_rate': 0.2, 'epochs': 1, 'neurons': 64, 'weight_constraint': 2}\n",
      "Mean = 0.540563 (std=0.025815) with: {'batch_size': 200, 'dropout_rate': 0.2, 'epochs': 1, 'neurons': 64, 'weight_constraint': 3}\n",
      "Mean = 0.542729 (std=0.017355) with: {'batch_size': 200, 'dropout_rate': 0.2, 'epochs': 5, 'neurons': 10, 'weight_constraint': 1}\n",
      "Mean = 0.518241 (std=0.023677) with: {'batch_size': 200, 'dropout_rate': 0.2, 'epochs': 5, 'neurons': 10, 'weight_constraint': 2}\n",
      "Mean = 0.531901 (std=0.004712) with: {'batch_size': 200, 'dropout_rate': 0.2, 'epochs': 5, 'neurons': 10, 'weight_constraint': 3}\n",
      "Mean = 0.571214 (std=0.014757) with: {'batch_size': 200, 'dropout_rate': 0.2, 'epochs': 5, 'neurons': 32, 'weight_constraint': 1}\n",
      "Mean = 0.572214 (std=0.016745) with: {'batch_size': 200, 'dropout_rate': 0.2, 'epochs': 5, 'neurons': 32, 'weight_constraint': 2}\n",
      "Mean = 0.568049 (std=0.019866) with: {'batch_size': 200, 'dropout_rate': 0.2, 'epochs': 5, 'neurons': 32, 'weight_constraint': 3}\n",
      "Mean = 0.642679 (std=0.007623) with: {'batch_size': 200, 'dropout_rate': 0.2, 'epochs': 5, 'neurons': 64, 'weight_constraint': 1}\n",
      "Mean = 0.664001 (std=0.015915) with: {'batch_size': 200, 'dropout_rate': 0.2, 'epochs': 5, 'neurons': 64, 'weight_constraint': 2}\n",
      "Mean = 0.670831 (std=0.004087) with: {'batch_size': 200, 'dropout_rate': 0.2, 'epochs': 5, 'neurons': 64, 'weight_constraint': 3}\n",
      "Mean = 0.548059 (std=0.002493) with: {'batch_size': 200, 'dropout_rate': 0.2, 'epochs': 10, 'neurons': 10, 'weight_constraint': 1}\n",
      "Mean = 0.548892 (std=0.016811) with: {'batch_size': 200, 'dropout_rate': 0.2, 'epochs': 10, 'neurons': 10, 'weight_constraint': 2}\n",
      "Mean = 0.529235 (std=0.018916) with: {'batch_size': 200, 'dropout_rate': 0.2, 'epochs': 10, 'neurons': 10, 'weight_constraint': 3}\n",
      "Mean = 0.651008 (std=0.011266) with: {'batch_size': 200, 'dropout_rate': 0.2, 'epochs': 10, 'neurons': 32, 'weight_constraint': 1}\n",
      "Mean = 0.654839 (std=0.019322) with: {'batch_size': 200, 'dropout_rate': 0.2, 'epochs': 10, 'neurons': 32, 'weight_constraint': 2}\n",
      "Mean = 0.668666 (std=0.008481) with: {'batch_size': 200, 'dropout_rate': 0.2, 'epochs': 10, 'neurons': 32, 'weight_constraint': 3}\n",
      "Mean = 0.711811 (std=0.003857) with: {'batch_size': 200, 'dropout_rate': 0.2, 'epochs': 10, 'neurons': 64, 'weight_constraint': 1}\n",
      "Mean = 0.725637 (std=0.004947) with: {'batch_size': 200, 'dropout_rate': 0.2, 'epochs': 10, 'neurons': 64, 'weight_constraint': 2}\n",
      "Mean = 0.728969 (std=0.003116) with: {'batch_size': 200, 'dropout_rate': 0.2, 'epochs': 10, 'neurons': 64, 'weight_constraint': 3}\n",
      "Mean = 0.489255 (std=0.000707) with: {'batch_size': 200, 'dropout_rate': 0.4, 'epochs': 1, 'neurons': 10, 'weight_constraint': 1}\n",
      "Mean = 0.499750 (std=0.018889) with: {'batch_size': 200, 'dropout_rate': 0.4, 'epochs': 1, 'neurons': 10, 'weight_constraint': 2}\n",
      "Mean = 0.482092 (std=0.037791) with: {'batch_size': 200, 'dropout_rate': 0.4, 'epochs': 1, 'neurons': 10, 'weight_constraint': 3}\n",
      "Mean = 0.531901 (std=0.010768) with: {'batch_size': 200, 'dropout_rate': 0.4, 'epochs': 1, 'neurons': 32, 'weight_constraint': 1}\n",
      "Mean = 0.521739 (std=0.006011) with: {'batch_size': 200, 'dropout_rate': 0.4, 'epochs': 1, 'neurons': 32, 'weight_constraint': 2}\n",
      "Mean = 0.537231 (std=0.026860) with: {'batch_size': 200, 'dropout_rate': 0.4, 'epochs': 1, 'neurons': 32, 'weight_constraint': 3}\n",
      "Mean = 0.549559 (std=0.009676) with: {'batch_size': 200, 'dropout_rate': 0.4, 'epochs': 1, 'neurons': 64, 'weight_constraint': 1}\n",
      "Mean = 0.547726 (std=0.031217) with: {'batch_size': 200, 'dropout_rate': 0.4, 'epochs': 1, 'neurons': 64, 'weight_constraint': 2}\n",
      "Mean = 0.572047 (std=0.011318) with: {'batch_size': 200, 'dropout_rate': 0.4, 'epochs': 1, 'neurons': 64, 'weight_constraint': 3}\n",
      "Mean = 0.520073 (std=0.018723) with: {'batch_size': 200, 'dropout_rate': 0.4, 'epochs': 5, 'neurons': 10, 'weight_constraint': 1}\n",
      "Mean = 0.535732 (std=0.016214) with: {'batch_size': 200, 'dropout_rate': 0.4, 'epochs': 5, 'neurons': 10, 'weight_constraint': 2}\n",
      "Mean = 0.523238 (std=0.006742) with: {'batch_size': 200, 'dropout_rate': 0.4, 'epochs': 5, 'neurons': 10, 'weight_constraint': 3}\n",
      "Mean = 0.538897 (std=0.017713) with: {'batch_size': 200, 'dropout_rate': 0.4, 'epochs': 5, 'neurons': 32, 'weight_constraint': 1}\n",
      "Mean = 0.572047 (std=0.018878) with: {'batch_size': 200, 'dropout_rate': 0.4, 'epochs': 5, 'neurons': 32, 'weight_constraint': 2}\n",
      "Mean = 0.563718 (std=0.013819) with: {'batch_size': 200, 'dropout_rate': 0.4, 'epochs': 5, 'neurons': 32, 'weight_constraint': 3}\n",
      "Mean = 0.623188 (std=0.010796) with: {'batch_size': 200, 'dropout_rate': 0.4, 'epochs': 5, 'neurons': 64, 'weight_constraint': 1}\n",
      "Mean = 0.638847 (std=0.010358) with: {'batch_size': 200, 'dropout_rate': 0.4, 'epochs': 5, 'neurons': 64, 'weight_constraint': 2}\n",
      "Mean = 0.653507 (std=0.008793) with: {'batch_size': 200, 'dropout_rate': 0.4, 'epochs': 5, 'neurons': 64, 'weight_constraint': 3}\n",
      "Mean = 0.523072 (std=0.006507) with: {'batch_size': 200, 'dropout_rate': 0.4, 'epochs': 10, 'neurons': 10, 'weight_constraint': 1}\n",
      "Mean = 0.531401 (std=0.002391) with: {'batch_size': 200, 'dropout_rate': 0.4, 'epochs': 10, 'neurons': 10, 'weight_constraint': 2}\n",
      "Mean = 0.529735 (std=0.023108) with: {'batch_size': 200, 'dropout_rate': 0.4, 'epochs': 10, 'neurons': 10, 'weight_constraint': 3}\n",
      "Mean = 0.620856 (std=0.009326) with: {'batch_size': 200, 'dropout_rate': 0.4, 'epochs': 10, 'neurons': 32, 'weight_constraint': 1}\n",
      "Mean = 0.651508 (std=0.009127) with: {'batch_size': 200, 'dropout_rate': 0.4, 'epochs': 10, 'neurons': 32, 'weight_constraint': 2}\n",
      "Mean = 0.623688 (std=0.001080) with: {'batch_size': 200, 'dropout_rate': 0.4, 'epochs': 10, 'neurons': 32, 'weight_constraint': 3}\n",
      "Mean = 0.692154 (std=0.011959) with: {'batch_size': 200, 'dropout_rate': 0.4, 'epochs': 10, 'neurons': 64, 'weight_constraint': 1}\n",
      "Mean = 0.723138 (std=0.004706) with: {'batch_size': 200, 'dropout_rate': 0.4, 'epochs': 10, 'neurons': 64, 'weight_constraint': 2}\n",
      "Mean = 0.717641 (std=0.003892) with: {'batch_size': 200, 'dropout_rate': 0.4, 'epochs': 10, 'neurons': 64, 'weight_constraint': 3}\n",
      "Mean = 0.406797 (std=0.109154) with: {'batch_size': 400, 'dropout_rate': 0.0, 'epochs': 1, 'neurons': 10, 'weight_constraint': 1}\n",
      "Mean = 0.468099 (std=0.051132) with: {'batch_size': 400, 'dropout_rate': 0.0, 'epochs': 1, 'neurons': 10, 'weight_constraint': 2}\n",
      "Mean = 0.393137 (std=0.061207) with: {'batch_size': 400, 'dropout_rate': 0.0, 'epochs': 1, 'neurons': 10, 'weight_constraint': 3}\n",
      "Mean = 0.498917 (std=0.023696) with: {'batch_size': 400, 'dropout_rate': 0.0, 'epochs': 1, 'neurons': 32, 'weight_constraint': 1}\n",
      "Mean = 0.426787 (std=0.097857) with: {'batch_size': 400, 'dropout_rate': 0.0, 'epochs': 1, 'neurons': 32, 'weight_constraint': 2}\n",
      "Mean = 0.463768 (std=0.045123) with: {'batch_size': 400, 'dropout_rate': 0.0, 'epochs': 1, 'neurons': 32, 'weight_constraint': 3}\n",
      "Mean = 0.545894 (std=0.023491) with: {'batch_size': 400, 'dropout_rate': 0.0, 'epochs': 1, 'neurons': 64, 'weight_constraint': 1}\n",
      "Mean = 0.527070 (std=0.003273) with: {'batch_size': 400, 'dropout_rate': 0.0, 'epochs': 1, 'neurons': 64, 'weight_constraint': 2}\n",
      "Mean = 0.519074 (std=0.006905) with: {'batch_size': 400, 'dropout_rate': 0.0, 'epochs': 1, 'neurons': 64, 'weight_constraint': 3}\n",
      "Mean = 0.520906 (std=0.017609) with: {'batch_size': 400, 'dropout_rate': 0.0, 'epochs': 5, 'neurons': 10, 'weight_constraint': 1}\n",
      "Mean = 0.528402 (std=0.003090) with: {'batch_size': 400, 'dropout_rate': 0.0, 'epochs': 5, 'neurons': 10, 'weight_constraint': 2}\n",
      "Mean = 0.508246 (std=0.013435) with: {'batch_size': 400, 'dropout_rate': 0.0, 'epochs': 5, 'neurons': 10, 'weight_constraint': 3}\n",
      "Mean = 0.539564 (std=0.018674) with: {'batch_size': 400, 'dropout_rate': 0.0, 'epochs': 5, 'neurons': 32, 'weight_constraint': 1}\n",
      "Mean = 0.559720 (std=0.024608) with: {'batch_size': 400, 'dropout_rate': 0.0, 'epochs': 5, 'neurons': 32, 'weight_constraint': 2}\n",
      "Mean = 0.571381 (std=0.038960) with: {'batch_size': 400, 'dropout_rate': 0.0, 'epochs': 5, 'neurons': 32, 'weight_constraint': 3}\n",
      "Mean = 0.600533 (std=0.022808) with: {'batch_size': 400, 'dropout_rate': 0.0, 'epochs': 5, 'neurons': 64, 'weight_constraint': 1}\n",
      "Mean = 0.594369 (std=0.029437) with: {'batch_size': 400, 'dropout_rate': 0.0, 'epochs': 5, 'neurons': 64, 'weight_constraint': 2}\n",
      "Mean = 0.599034 (std=0.014463) with: {'batch_size': 400, 'dropout_rate': 0.0, 'epochs': 5, 'neurons': 64, 'weight_constraint': 3}\n",
      "Mean = 0.520240 (std=0.015306) with: {'batch_size': 400, 'dropout_rate': 0.0, 'epochs': 10, 'neurons': 10, 'weight_constraint': 1}\n",
      "Mean = 0.526070 (std=0.005890) with: {'batch_size': 400, 'dropout_rate': 0.0, 'epochs': 10, 'neurons': 10, 'weight_constraint': 2}\n",
      "Mean = 0.538731 (std=0.022912) with: {'batch_size': 400, 'dropout_rate': 0.0, 'epochs': 10, 'neurons': 10, 'weight_constraint': 3}\n",
      "Mean = 0.563718 (std=0.010250) with: {'batch_size': 400, 'dropout_rate': 0.0, 'epochs': 10, 'neurons': 32, 'weight_constraint': 1}\n",
      "Mean = 0.576378 (std=0.010752) with: {'batch_size': 400, 'dropout_rate': 0.0, 'epochs': 10, 'neurons': 32, 'weight_constraint': 2}\n",
      "Mean = 0.594536 (std=0.015678) with: {'batch_size': 400, 'dropout_rate': 0.0, 'epochs': 10, 'neurons': 32, 'weight_constraint': 3}\n",
      "Mean = 0.638014 (std=0.007303) with: {'batch_size': 400, 'dropout_rate': 0.0, 'epochs': 10, 'neurons': 64, 'weight_constraint': 1}\n",
      "Mean = 0.674329 (std=0.012134) with: {'batch_size': 400, 'dropout_rate': 0.0, 'epochs': 10, 'neurons': 64, 'weight_constraint': 2}\n",
      "Mean = 0.661503 (std=0.020387) with: {'batch_size': 400, 'dropout_rate': 0.0, 'epochs': 10, 'neurons': 64, 'weight_constraint': 3}\n",
      "Mean = 0.402132 (std=0.043503) with: {'batch_size': 400, 'dropout_rate': 0.2, 'epochs': 1, 'neurons': 10, 'weight_constraint': 1}\n",
      "Mean = 0.402965 (std=0.093659) with: {'batch_size': 400, 'dropout_rate': 0.2, 'epochs': 1, 'neurons': 10, 'weight_constraint': 2}\n",
      "Mean = 0.507580 (std=0.028692) with: {'batch_size': 400, 'dropout_rate': 0.2, 'epochs': 1, 'neurons': 10, 'weight_constraint': 3}\n",
      "Mean = 0.478427 (std=0.026078) with: {'batch_size': 400, 'dropout_rate': 0.2, 'epochs': 1, 'neurons': 32, 'weight_constraint': 1}\n",
      "Mean = 0.470098 (std=0.050779) with: {'batch_size': 400, 'dropout_rate': 0.2, 'epochs': 1, 'neurons': 32, 'weight_constraint': 2}\n",
      "Mean = 0.478261 (std=0.026604) with: {'batch_size': 400, 'dropout_rate': 0.2, 'epochs': 1, 'neurons': 32, 'weight_constraint': 3}\n",
      "Mean = 0.520906 (std=0.019425) with: {'batch_size': 400, 'dropout_rate': 0.2, 'epochs': 1, 'neurons': 64, 'weight_constraint': 1}\n",
      "Mean = 0.542395 (std=0.037225) with: {'batch_size': 400, 'dropout_rate': 0.2, 'epochs': 1, 'neurons': 64, 'weight_constraint': 2}\n",
      "Mean = 0.537065 (std=0.012250) with: {'batch_size': 400, 'dropout_rate': 0.2, 'epochs': 1, 'neurons': 64, 'weight_constraint': 3}\n",
      "Mean = 0.519240 (std=0.013819) with: {'batch_size': 400, 'dropout_rate': 0.2, 'epochs': 5, 'neurons': 10, 'weight_constraint': 1}\n",
      "Mean = 0.520740 (std=0.022215) with: {'batch_size': 400, 'dropout_rate': 0.2, 'epochs': 5, 'neurons': 10, 'weight_constraint': 2}\n",
      "Mean = 0.523072 (std=0.006179) with: {'batch_size': 400, 'dropout_rate': 0.2, 'epochs': 5, 'neurons': 10, 'weight_constraint': 3}\n",
      "Mean = 0.548726 (std=0.028069) with: {'batch_size': 400, 'dropout_rate': 0.2, 'epochs': 5, 'neurons': 32, 'weight_constraint': 1}\n",
      "Mean = 0.582042 (std=0.029567) with: {'batch_size': 400, 'dropout_rate': 0.2, 'epochs': 5, 'neurons': 32, 'weight_constraint': 2}\n",
      "Mean = 0.543895 (std=0.024214) with: {'batch_size': 400, 'dropout_rate': 0.2, 'epochs': 5, 'neurons': 32, 'weight_constraint': 3}\n",
      "Mean = 0.585041 (std=0.011730) with: {'batch_size': 400, 'dropout_rate': 0.2, 'epochs': 5, 'neurons': 64, 'weight_constraint': 1}\n",
      "Mean = 0.609695 (std=0.013903) with: {'batch_size': 400, 'dropout_rate': 0.2, 'epochs': 5, 'neurons': 64, 'weight_constraint': 2}\n",
      "Mean = 0.605697 (std=0.008130) with: {'batch_size': 400, 'dropout_rate': 0.2, 'epochs': 5, 'neurons': 64, 'weight_constraint': 3}\n",
      "Mean = 0.519074 (std=0.001649) with: {'batch_size': 400, 'dropout_rate': 0.2, 'epochs': 10, 'neurons': 10, 'weight_constraint': 1}\n",
      "Mean = 0.519574 (std=0.016129) with: {'batch_size': 400, 'dropout_rate': 0.2, 'epochs': 10, 'neurons': 10, 'weight_constraint': 2}\n",
      "Mean = 0.514409 (std=0.017433) with: {'batch_size': 400, 'dropout_rate': 0.2, 'epochs': 10, 'neurons': 10, 'weight_constraint': 3}\n",
      "Mean = 0.564051 (std=0.014793) with: {'batch_size': 400, 'dropout_rate': 0.2, 'epochs': 10, 'neurons': 32, 'weight_constraint': 1}\n",
      "Mean = 0.585374 (std=0.023512) with: {'batch_size': 400, 'dropout_rate': 0.2, 'epochs': 10, 'neurons': 32, 'weight_constraint': 2}\n",
      "Mean = 0.554723 (std=0.026457) with: {'batch_size': 400, 'dropout_rate': 0.2, 'epochs': 10, 'neurons': 32, 'weight_constraint': 3}\n",
      "Mean = 0.661503 (std=0.001545) with: {'batch_size': 400, 'dropout_rate': 0.2, 'epochs': 10, 'neurons': 64, 'weight_constraint': 1}\n",
      "Mean = 0.656339 (std=0.007659) with: {'batch_size': 400, 'dropout_rate': 0.2, 'epochs': 10, 'neurons': 64, 'weight_constraint': 2}\n",
      "Mean = 0.670165 (std=0.010979) with: {'batch_size': 400, 'dropout_rate': 0.2, 'epochs': 10, 'neurons': 64, 'weight_constraint': 3}\n",
      "Mean = 0.381976 (std=0.076366) with: {'batch_size': 400, 'dropout_rate': 0.4, 'epochs': 1, 'neurons': 10, 'weight_constraint': 1}\n",
      "Mean = 0.469599 (std=0.041356) with: {'batch_size': 400, 'dropout_rate': 0.4, 'epochs': 1, 'neurons': 10, 'weight_constraint': 2}\n",
      "Mean = 0.372314 (std=0.054095) with: {'batch_size': 400, 'dropout_rate': 0.4, 'epochs': 1, 'neurons': 10, 'weight_constraint': 3}\n",
      "Mean = 0.503082 (std=0.030907) with: {'batch_size': 400, 'dropout_rate': 0.4, 'epochs': 1, 'neurons': 32, 'weight_constraint': 1}\n",
      "Mean = 0.465434 (std=0.036335) with: {'batch_size': 400, 'dropout_rate': 0.4, 'epochs': 1, 'neurons': 32, 'weight_constraint': 2}\n",
      "Mean = 0.446943 (std=0.070323) with: {'batch_size': 400, 'dropout_rate': 0.4, 'epochs': 1, 'neurons': 32, 'weight_constraint': 3}\n",
      "Mean = 0.505414 (std=0.006634) with: {'batch_size': 400, 'dropout_rate': 0.4, 'epochs': 1, 'neurons': 64, 'weight_constraint': 1}\n",
      "Mean = 0.514243 (std=0.031531) with: {'batch_size': 400, 'dropout_rate': 0.4, 'epochs': 1, 'neurons': 64, 'weight_constraint': 2}\n",
      "Mean = 0.544894 (std=0.006596) with: {'batch_size': 400, 'dropout_rate': 0.4, 'epochs': 1, 'neurons': 64, 'weight_constraint': 3}\n",
      "Mean = 0.510245 (std=0.013228) with: {'batch_size': 400, 'dropout_rate': 0.4, 'epochs': 5, 'neurons': 10, 'weight_constraint': 1}\n",
      "Mean = 0.534233 (std=0.021088) with: {'batch_size': 400, 'dropout_rate': 0.4, 'epochs': 5, 'neurons': 10, 'weight_constraint': 2}\n",
      "Mean = 0.520906 (std=0.019058) with: {'batch_size': 400, 'dropout_rate': 0.4, 'epochs': 5, 'neurons': 10, 'weight_constraint': 3}\n",
      "Mean = 0.533900 (std=0.030400) with: {'batch_size': 400, 'dropout_rate': 0.4, 'epochs': 5, 'neurons': 32, 'weight_constraint': 1}\n",
      "Mean = 0.562219 (std=0.013379) with: {'batch_size': 400, 'dropout_rate': 0.4, 'epochs': 5, 'neurons': 32, 'weight_constraint': 2}\n",
      "Mean = 0.543062 (std=0.008755) with: {'batch_size': 400, 'dropout_rate': 0.4, 'epochs': 5, 'neurons': 32, 'weight_constraint': 3}\n",
      "Mean = 0.565384 (std=0.019331) with: {'batch_size': 400, 'dropout_rate': 0.4, 'epochs': 5, 'neurons': 64, 'weight_constraint': 1}\n",
      "Mean = 0.579210 (std=0.014141) with: {'batch_size': 400, 'dropout_rate': 0.4, 'epochs': 5, 'neurons': 64, 'weight_constraint': 2}\n",
      "Mean = 0.576045 (std=0.014336) with: {'batch_size': 400, 'dropout_rate': 0.4, 'epochs': 5, 'neurons': 64, 'weight_constraint': 3}\n",
      "Mean = 0.516575 (std=0.016736) with: {'batch_size': 400, 'dropout_rate': 0.4, 'epochs': 10, 'neurons': 10, 'weight_constraint': 1}\n",
      "Mean = 0.512910 (std=0.007188) with: {'batch_size': 400, 'dropout_rate': 0.4, 'epochs': 10, 'neurons': 10, 'weight_constraint': 2}\n",
      "Mean = 0.525237 (std=0.017546) with: {'batch_size': 400, 'dropout_rate': 0.4, 'epochs': 10, 'neurons': 10, 'weight_constraint': 3}\n",
      "Mean = 0.557388 (std=0.010775) with: {'batch_size': 400, 'dropout_rate': 0.4, 'epochs': 10, 'neurons': 32, 'weight_constraint': 1}\n",
      "Mean = 0.579710 (std=0.020609) with: {'batch_size': 400, 'dropout_rate': 0.4, 'epochs': 10, 'neurons': 32, 'weight_constraint': 2}\n",
      "Mean = 0.565217 (std=0.011002) with: {'batch_size': 400, 'dropout_rate': 0.4, 'epochs': 10, 'neurons': 32, 'weight_constraint': 3}\n",
      "Mean = 0.629019 (std=0.010737) with: {'batch_size': 400, 'dropout_rate': 0.4, 'epochs': 10, 'neurons': 64, 'weight_constraint': 1}\n",
      "Mean = 0.641846 (std=0.013015) with: {'batch_size': 400, 'dropout_rate': 0.4, 'epochs': 10, 'neurons': 64, 'weight_constraint': 2}\n",
      "Mean = 0.653007 (std=0.010334) with: {'batch_size': 400, 'dropout_rate': 0.4, 'epochs': 10, 'neurons': 64, 'weight_constraint': 3}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"Mean = %f (std=%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff8c6a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
