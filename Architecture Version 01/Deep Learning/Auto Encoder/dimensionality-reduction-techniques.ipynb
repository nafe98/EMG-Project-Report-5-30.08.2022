{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from umap import UMAP\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.manifold import TSNE\n",
    "# Clearing up memory\n",
    "import gc\n",
    "\n",
    "# Featuretools for automated feature engineering\n",
    "import featuretools as ft\n",
    "import featuretools.variable_types as vtypes\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "# Modeling\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Evaluation of the model\n",
    "from sklearn.model_selection import KFold, train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "13dd09b5c29533bfe6e84ba2e8ffb2afcd8d6c77"
   },
   "outputs": [],
   "source": [
    "feature_matrix = pd.read_csv('../input/costa-rican-poverty-derived-data/ft_2000.csv')\n",
    "feature_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ae44c82bf7ae8b5ea6815d7066fe49c53e7d4b19",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_matrix['SUM(ind.rez_esc / escolari)'] = feature_matrix['SUM(ind.rez_esc / escolari)'].astype(np.float32)\n",
    "feature_matrix['SUM(ind.age / escolari)'] = feature_matrix['SUM(ind.age / escolari)'].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "72e05bfb48f589bc0c6e541dacd526db73f6cde9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in feature_matrix:\n",
    "    if feature_matrix[col].dtype == 'object':\n",
    "        if col != 'idhogar':\n",
    "            feature_matrix[col] = feature_matrix[col].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a1504aa24f6a4b6090bbca1868b3b7c64b23766a"
   },
   "outputs": [],
   "source": [
    "feature_matrix.columns[np.where(feature_matrix.dtypes == 'object')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0d548dfac93f85248d789326f2fed941b0a7b91d"
   },
   "outputs": [],
   "source": [
    "missing_threshold = 0.95\n",
    "correlation_threshold = 0.99\n",
    "\n",
    "\n",
    "train = feature_matrix[feature_matrix['Target'].notnull()]\n",
    "test = feature_matrix[feature_matrix['Target'].isnull()]\n",
    "\n",
    "train_ids = list(train.pop('idhogar'))\n",
    "test_ids = list(test.pop('idhogar'))\n",
    "\n",
    "feature_matrix = feature_matrix.replace({np.inf: np.nan, -np.inf:np.nan})\n",
    "n_features_start = feature_matrix.shape[1]\n",
    "print('Original shape: ', feature_matrix.shape)\n",
    "\n",
    "# Find missing and percentage\n",
    "missing = pd.DataFrame(feature_matrix.isnull().sum())\n",
    "missing['fraction'] = missing[0] / feature_matrix.shape[0]\n",
    "missing.sort_values('fraction', ascending = False, inplace = True)\n",
    "\n",
    "# Missing above threshold\n",
    "missing_cols = list(missing[missing['fraction'] > missing_threshold].index)\n",
    "n_missing_cols = len(missing_cols)\n",
    "\n",
    "# Remove missing columns\n",
    "feature_matrix = feature_matrix[[x for x in feature_matrix if x not in missing_cols]]\n",
    "print('{} missing columns with threshold: {}.'.format(n_missing_cols, missing_threshold))\n",
    "\n",
    "# Zero variance\n",
    "unique_counts = pd.DataFrame(feature_matrix.nunique()).sort_values(0, ascending = True)\n",
    "zero_variance_cols = list(unique_counts[unique_counts[0] == 1].index)\n",
    "n_zero_variance_cols = len(zero_variance_cols)\n",
    "\n",
    "# Remove zero variance columns\n",
    "feature_matrix = feature_matrix[[x for x in feature_matrix if x not in zero_variance_cols]]\n",
    "print('{} zero variance columns.'.format(n_zero_variance_cols))\n",
    "\n",
    "# Correlations\n",
    "corr_matrix = feature_matrix.corr()\n",
    "\n",
    "# Extract the upper triangle of the correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k = 1).astype(np.bool))\n",
    "\n",
    "# Select the features with correlations above the threshold\n",
    "# Need to use the absolute value\n",
    "to_drop = [column for column in upper.columns if any(upper[column].abs() > correlation_threshold)]\n",
    "\n",
    "n_collinear = len(to_drop)\n",
    "\n",
    "feature_matrix = feature_matrix[[x for x in feature_matrix if x not in to_drop]]\n",
    "print('{} collinear columns removed with correlation above {}.'.format(n_collinear,  correlation_threshold))\n",
    "\n",
    "total_removed = n_missing_cols + n_zero_variance_cols + n_collinear\n",
    "\n",
    "print('Total columns removed: ', total_removed)\n",
    "print('Shape after feature selection: {}.'.format(feature_matrix.shape))\n",
    "\n",
    "# Remove columns derived from the Target\n",
    "drop_cols = []\n",
    "for col in feature_matrix:\n",
    "    if col == 'Target':\n",
    "        pass\n",
    "    else:\n",
    "        if 'Target' in col:\n",
    "            drop_cols.append(col)\n",
    "\n",
    "feature_matrix = feature_matrix[[x for x in feature_matrix if x not in drop_cols]]    \n",
    "\n",
    "# Extract out training and testing data\n",
    "train = feature_matrix[feature_matrix['Target'].notnull()]\n",
    "test = feature_matrix[feature_matrix['Target'].isnull()]\n",
    "\n",
    "train_ids = list(train.pop('idhogar'))\n",
    "test_ids = list(test.pop('idhogar'))\n",
    "\n",
    "train_labels = np.array(train.pop('Target')).reshape((-1, ))\n",
    "test = test.drop(columns = 'Target')\n",
    "\n",
    "train = train.replace({np.inf: np.nan, -np.inf: np.nan})\n",
    "test = test.replace({np.inf: np.nan, -np.inf: np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "aa0daf71bec4eaa1c4ecb73a9d3665cdd1777032"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "feature_list = list(train.columns)\n",
    "\n",
    "imputer = SimpleImputer(strategy = 'median')\n",
    "train = imputer.fit_transform(train)\n",
    "test = imputer.transform(test)\n",
    "\n",
    "train_df = pd.DataFrame(train, columns = feature_list)\n",
    "test_df = pd.DataFrame(test, columns = feature_list)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ad2e1bc9a085b158e9f6181bd5eba220434bcf35",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = train_df.astype(np.float32)\n",
    "test_df = test_df.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "62c0c94e95ed4e2fd37a560c9d73cb34ceb1b545",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "n_components = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "961c71e5bf9bc6faae5d271cad7d0ebd53dd228a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "umap = UMAP(n_components=n_components)\n",
    "pca = PCA(n_components=n_components)\n",
    "ica = FastICA(n_components=n_components)\n",
    "tsne = TSNE(n_components=n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4ece588d4a488ea48f7f11154e2244fe5c30464c"
   },
   "outputs": [],
   "source": [
    "for method, name in zip([umap, pca, ica], ['umap', 'pca', 'ica']):\n",
    "    \n",
    "    if name == 'umap':\n",
    "        start = timer()\n",
    "        reduction = method.fit_transform(train, train_labels)\n",
    "        test_reduction = method.transform(test)\n",
    "        end = timer()\n",
    "    \n",
    "    else:\n",
    "        start = timer()\n",
    "        reduction = method.fit_transform(train)\n",
    "        test_reduction = method.transform(test)\n",
    "        end = timer()\n",
    "        \n",
    "    print(f'Method: {name} {round(end - start, 2)} seconds elapsed.')\n",
    "    train_df['%s_c1' % name] = reduction[:, 0]\n",
    "    train_df['%s_c2' % name] = reduction[:, 1]\n",
    "    train_df['%s_c3' % name] = reduction[:, 2]\n",
    "    \n",
    "    test_df['%s_c1' % name] = test_reduction[:, 0]\n",
    "    test_df['%s_c2' % name] = test_reduction[:, 1]\n",
    "    test_df['%s_c3' % name] = test_reduction[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "acddfd09765f5755743fe43c5f5f4801e4c4202a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df['label'] = train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "406f77e845e04281ad917f7394163eacc31cbe3d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "cmap = plt.get_cmap('tab10', 4)\n",
    "\n",
    "for method, name in zip([umap, pca, ica], ['umap', 'pca', 'ica']):\n",
    "    fig = plt.figure(figsize = (8, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    p = ax.scatter(train_df['%s_c1' % name], train_df['%s_c2'  % name], train_df['%s_c3'  % name], c = train_df['label'].astype(int), cmap = cmap)\n",
    "    plt.title(f'{name.capitalize()}')\n",
    "    fig.colorbar(p, aspect = 4, ticks = [1, 2, 3, 4])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cd636cf78c5faec5e397c15b2e816b1c9055db4a"
   },
   "outputs": [],
   "source": [
    "test_comp = pd.read_csv('../input/costa-rican-household-poverty-prediction/test.csv')\n",
    "submission_base = test_comp.loc[:, ['idhogar', 'Id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ba7af7e60b1519b047aa08fc0b79f4449ff42c2c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def macro_f1_score(labels, predictions):\n",
    "    # Reshape the predictions as needed\n",
    "    predictions = predictions.reshape(len(np.unique(labels)), -1 ).argmax(axis = 0)\n",
    "    \n",
    "    metric_value = f1_score(labels, predictions, average = 'macro')\n",
    "    \n",
    "    # Return is name, value, is_higher_better\n",
    "    return 'macro_f1', metric_value, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "911336fd8ae83e6c63958d3e95c16b99eb418456",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_gbm(features, labels, test_features, test_ids, nfolds = 5, return_preds = False):\n",
    "    \"\"\"Model using the GBM and cross validation.\n",
    "       Trains with early stopping on each fold.\n",
    "       Hyperparameters probably need to be tuned.\"\"\"\n",
    "    \n",
    "    feature_names = list(features.columns)\n",
    "    \n",
    "    # Model with hyperparameters selected from previous work\n",
    "    model = lgb.LGBMClassifier(boosting_type = 'gbdt', n_estimators = 10000, max_depth = -1,\n",
    "                               learning_rate = 0.025, metric = 'None', min_child_samples = 30,\n",
    "                               reg_alpha = 0.35, reg_lambda = 0.6, num_leaves = 15, \n",
    "                               colsample_bytree = 0.85, objective = 'multiclass', \n",
    "                               class_weight = 'balanced', \n",
    "                               n_jobs = -1)\n",
    "    \n",
    "    # Using stratified kfold cross validation\n",
    "    strkfold = StratifiedKFold(n_splits = nfolds, shuffle = True)\n",
    "    predictions = pd.DataFrame()\n",
    "    importances = np.zeros(len(feature_names))\n",
    "    \n",
    "    # Convert to arrays for indexing\n",
    "    features = np.array(features)\n",
    "    test_features = np.array(test_features)\n",
    "    labels = np.array(labels).reshape((-1 ))\n",
    "    \n",
    "    valid_scores = []\n",
    "    \n",
    "    # Iterate through the folds\n",
    "    for i, (train_indices, valid_indices) in enumerate(strkfold.split(features, labels)):\n",
    "        # Dataframe for \n",
    "        fold_predictions = pd.DataFrame()\n",
    "        \n",
    "        # Training and validation data\n",
    "        X_train = features[train_indices]\n",
    "        X_valid = features[valid_indices]\n",
    "        y_train = labels[train_indices]\n",
    "        y_valid = labels[valid_indices]\n",
    "        \n",
    "        # Train with early stopping\n",
    "        model.fit(X_train, y_train, early_stopping_rounds = 100, \n",
    "                  eval_metric = macro_f1_score,\n",
    "                  eval_set = [(X_train, y_train), (X_valid, y_valid)],\n",
    "                  eval_names = ['train', 'valid'],\n",
    "                  verbose = 200)\n",
    "        \n",
    "        # Record the validation fold score\n",
    "        valid_scores.append(model.best_score_['valid']['macro_f1'])\n",
    "        \n",
    "        # Make predictions from the fold\n",
    "        fold_probabilitites = model.predict_proba(test_features)\n",
    "        \n",
    "        # Record each prediction for each class as a column\n",
    "        for j in range(4):\n",
    "            fold_predictions[(j + 1)] = fold_probabilitites[:, j]\n",
    "            \n",
    "        fold_predictions['idhogar'] = test_ids\n",
    "        fold_predictions['fold'] = (i+1)\n",
    "        predictions = predictions.append(fold_predictions)\n",
    "        \n",
    "        importances += model.feature_importances_ / nfolds    \n",
    "\n",
    "    feature_importances = pd.DataFrame({'feature': feature_names,\n",
    "                                        'importance': importances})\n",
    "    valid_scores = np.array(valid_scores)\n",
    "    print(f'{nfolds} cross validation score: {round(valid_scores.mean(), 5)} with std: {round(valid_scores.std(), 5)}.')\n",
    "    \n",
    "    # If we want to examine predictions don't average over folds\n",
    "    if return_preds:\n",
    "        predictions['Target'] = predictions[[1, 2, 3, 4]].idxmax(axis = 1)\n",
    "        predictions['confidence'] = predictions[[1, 2, 3, 4]].max(axis = 1)\n",
    "        return predictions, feature_importances\n",
    "    \n",
    "    # Average the predictions over folds\n",
    "    predictions = predictions.groupby('idhogar', as_index = False).mean()\n",
    "    \n",
    "    # Find the class and associated probability\n",
    "    predictions['Target'] = predictions[[1, 2, 3, 4]].idxmax(axis = 1)\n",
    "    predictions['confidence'] = predictions[[1, 2, 3, 4]].max(axis = 1)\n",
    "    predictions = predictions.drop(columns = ['fold'])\n",
    "    \n",
    "    # Merge with the base to have one prediction for each individual\n",
    "    submission = submission_base.merge(predictions[['idhogar', 'Target']], \n",
    "                                       on = 'idhogar', how = 'left').drop(columns = ['idhogar'])\n",
    "        \n",
    "    submission['Target'] = submission['Target'].fillna(4).astype(np.int8)\n",
    "    \n",
    "    # return the submission and feature importances\n",
    "    return submission, feature_importances, valid_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "91092bb49f903f4ff425d009a387aac46b8310af"
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "384adcd6ca4327fdbd96ec7c28ab9d8983c27065",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in train_df:\n",
    "    if 'Target' in col:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4751d0e7d66050f30521853b633f5ed322b58659"
   },
   "outputs": [],
   "source": [
    "predictions, fi = model_gbm(train_df.drop(columns = 'label'), train_labels, \n",
    "                                   test_df, test_ids, return_preds = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c15e6524c3f315bab0a137dc85a20b6649430860"
   },
   "outputs": [],
   "source": [
    "fi.sort_values('importance').dropna().tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b013e46c0612522f05a7ad7ff01ebd3e5aa319ca"
   },
   "outputs": [],
   "source": [
    "submission, fi, scores = model_gbm(train_df.drop(columns = 'label'), train_labels, \n",
    "                                   test_df, test_ids, return_preds = False)\n",
    "\n",
    "submission.to_csv('dimension_reduction.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "36f0a25acc77267c47406a0cb5de1b1bd42343db"
   },
   "outputs": [],
   "source": [
    "fi.sort_values('importance').dropna().tail(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "67ae09ed945b6edddb2b86d81ee44b1e97f26099"
   },
   "outputs": [],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bd84a82e47f725a14caf0c6196d6c0ac42f8e8d4"
   },
   "outputs": [],
   "source": [
    "scores.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b458369ee1751db137b480f4430d02431f3f904f"
   },
   "source": [
    "# Try without giving labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e2031bd6fd42e355931c4fbd549e6fa30cd70c4f"
   },
   "outputs": [],
   "source": [
    "for method, name in zip([umap, pca, ica], ['umap', 'pca', 'ica']):\n",
    "    start = timer()\n",
    "    reduction = method.fit_transform(train)\n",
    "    test_reduction = method.transform(test)\n",
    "    end = timer()\n",
    "    print(f'Method: {name} {round(end - start, 2)} seconds elapsed.')\n",
    "    train_df['%s_c1' % name] = reduction[:, 0]\n",
    "    train_df['%s_c2' % name] = reduction[:, 1]\n",
    "    train_df['%s_c3' % name] = reduction[:, 2]\n",
    "    \n",
    "    test_df['%s_c1' % name] = test_reduction[:, 0]\n",
    "    test_df['%s_c2' % name] = test_reduction[:, 1]\n",
    "    test_df['%s_c3' % name] = test_reduction[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9f966d20067761f271e71e82085293e731d396eb"
   },
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap('tab10', 4)\n",
    "\n",
    "for method, name in zip([umap, pca, ica], ['umap', 'pca', 'ica']):\n",
    "    fig = plt.figure(figsize = (8, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    p = ax.scatter(train_df['%s_c1' % name], train_df['%s_c2'  % name], train_df['%s_c3'  % name], c = train_df['label'].astype(int), cmap = cmap)\n",
    "    plt.title(f'{name.capitalize()}')\n",
    "    fig.colorbar(p, aspect = 4, ticks = [1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f8d9454b2a707bc7d7dd011a3674e9c8b16789de"
   },
   "outputs": [],
   "source": [
    "submission, fi, scores = model_gbm(train_df.drop(columns = 'label'), train_labels, \n",
    "                                   test_df, test_ids, return_preds = False)\n",
    "\n",
    "submission.to_csv('dimension_reduction_nolabels.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f7cac8fc5cd6e2bb5ce192716416886154d1a045"
   },
   "outputs": [],
   "source": [
    "fi.sort_values('importance').dropna().tail(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6b68269ea087c7678d57aaa0ccf64dee8ba99d85",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
